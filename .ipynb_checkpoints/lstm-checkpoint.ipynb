{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkdir = \"/Users/chrisolen/Documents/uchicago_courses/deep_learning_and_image_recognition/finance/fin-portfolio-mvo/\"\n",
    "data_files = os.listdir(wkdir+'data')\n",
    "data_files.remove('.DS_Store')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(wkdir+'data/'+'data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'UST_10YR', 'UIVE_SP500VALUEETF', 'VNQ_VANGREALEST', 'USFFR',\n",
       "       'EMB_USDEMRGBOND', 'LQD_CORPBOND', 'MUB_MUNIBOND', 'SHY_1-3USTR',\n",
       "       'USDJPY', 'USDGBP', 'VIG_VANGDIV', 'IVV_SP500', 'USDRMB', 'CRUDOIL',\n",
       "       'CFE_VIX', 'EEM_MSCIEMERGING', 'USDEUR', 'XLE_ENERGYSPDR', 'SP500_GSCI',\n",
       "       'EFA_MSCIEAFE', 'TIP_TIPSBOND', 'UST_2YR', 'USDOIS', 'CHNGDP', 'USGDP',\n",
       "       'EZGDP', 'US_UNEMP', 'CHNGDP_Shock', 'USGDP_Shock', 'EZGDP_Shock',\n",
       "       'US_UNEMP_Shock', 'VNQ_VOL', 'EMB_VOL', 'LQD_VOL', 'MUB_VOL', 'VIG_VOL',\n",
       "       'IVV_VOL', 'EEM_VOL', 'EFA_VOL', 'XLE_VOL', 'SHY_VOL', 'TIP_VOL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features into macroeconomic indictors and portfolio:\n",
    "\n",
    "econ = ['CHNGDP','USGDP','EZGDP','US_UNEMP']\n",
    "\n",
    "shock = ['CHNGDP_Shock','USGDP_Shock','EZGDP_Shock','US_UNEMP_Shock']\n",
    "\n",
    "finstruments = ['UST_10YR','USFFR','USDRMB','CRUDOIL','CFE_VIX','USDEUR','UST_2YR',\n",
    "             'SP500_GSCI','USDOIS','UIVE_SP500VALUEETF','USDJPY','USDGBP']\n",
    "\n",
    "assets = ['VNQ_VANGREALEST','EMB_USDEMRGBOND','LQD_CORPBOND',\n",
    "            'MUB_MUNIBOND','SHY_1-3USTR','VIG_VANGDIV','IVV_SP500','EEM_MSCIEMERGING',\n",
    "            'XLE_ENERGYSPDR','EFA_MSCIEAFE','TIP_TIPSBOND']\n",
    "\n",
    "asset_vols = data.columns[-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VNQ_VANGREALEST</th>\n",
       "      <th>EMB_USDEMRGBOND</th>\n",
       "      <th>LQD_CORPBOND</th>\n",
       "      <th>MUB_MUNIBOND</th>\n",
       "      <th>SHY_1-3USTR</th>\n",
       "      <th>VIG_VANGDIV</th>\n",
       "      <th>IVV_SP500</th>\n",
       "      <th>EEM_MSCIEMERGING</th>\n",
       "      <th>XLE_ENERGYSPDR</th>\n",
       "      <th>EFA_MSCIEAFE</th>\n",
       "      <th>TIP_TIPSBOND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017507</td>\n",
       "      <td>-0.000754</td>\n",
       "      <td>-0.002072</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>0.013131</td>\n",
       "      <td>0.032254</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>-0.000748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>0.011717</td>\n",
       "      <td>-0.004173</td>\n",
       "      <td>-0.007582</td>\n",
       "      <td>-0.004498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000174</td>\n",
       "      <td>-0.003646</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>-0.014002</td>\n",
       "      <td>-0.012183</td>\n",
       "      <td>-0.028531</td>\n",
       "      <td>-0.012227</td>\n",
       "      <td>-0.021928</td>\n",
       "      <td>0.007393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.004192</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>-0.004140</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.014602</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>0.007749</td>\n",
       "      <td>0.004187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.020523</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>-0.018049</td>\n",
       "      <td>-0.025074</td>\n",
       "      <td>-0.046287</td>\n",
       "      <td>-0.042255</td>\n",
       "      <td>-0.032558</td>\n",
       "      <td>0.005093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>-0.004231</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>-0.015283</td>\n",
       "      <td>-0.018066</td>\n",
       "      <td>-0.007669</td>\n",
       "      <td>-0.024861</td>\n",
       "      <td>-0.022777</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.012830</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.003176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>0.013426</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>0.003080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>-0.002143</td>\n",
       "      <td>-0.005634</td>\n",
       "      <td>-0.005080</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>-0.005502</td>\n",
       "      <td>-0.004503</td>\n",
       "      <td>-0.008333</td>\n",
       "      <td>-0.008928</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>-0.002738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>-0.005270</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>-0.000862</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>-0.014620</td>\n",
       "      <td>-0.015595</td>\n",
       "      <td>-0.007163</td>\n",
       "      <td>-0.017204</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>-0.000943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2958 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VNQ_VANGREALEST  EMB_USDEMRGBOND  LQD_CORPBOND  MUB_MUNIBOND  \\\n",
       "1            0.017507        -0.000754     -0.002072      0.002550   \n",
       "2            0.015289         0.000881     -0.002946     -0.001470   \n",
       "3            0.000174        -0.003646      0.007275      0.001274   \n",
       "4           -0.004192         0.003451     -0.004140      0.004496   \n",
       "5           -0.020523         0.001662      0.005359      0.005446   \n",
       "...               ...              ...           ...           ...   \n",
       "2954        -0.004231        -0.000178     -0.000393      0.001754   \n",
       "2955         0.009630         0.004793      0.003922      0.002101   \n",
       "2956         0.006012         0.008728      0.004140      0.000000   \n",
       "2957        -0.002143        -0.005634     -0.005080     -0.000787   \n",
       "2958        -0.005270        -0.000972     -0.000862      0.002883   \n",
       "\n",
       "      SHY_1-3USTR  VIG_VANGDIV  IVV_SP500  EEM_MSCIEMERGING  XLE_ENERGYSPDR  \\\n",
       "1       -0.000484     0.008526   0.013131          0.032254        0.013098   \n",
       "2        0.000000     0.008820   0.006994          0.011717       -0.004173   \n",
       "3        0.002780    -0.014002  -0.012183         -0.028531       -0.012227   \n",
       "4        0.000362     0.006104   0.010139          0.014602        0.019647   \n",
       "5        0.000844    -0.018049  -0.025074         -0.046287       -0.042255   \n",
       "...           ...          ...        ...               ...             ...   \n",
       "2954     0.001061    -0.015283  -0.018066         -0.007669       -0.024861   \n",
       "2955     0.002119     0.005662   0.008287          0.012830        0.010756   \n",
       "2956    -0.000118     0.013426   0.013536          0.004403        0.006294   \n",
       "2957    -0.001059    -0.005502  -0.004503         -0.008333       -0.008928   \n",
       "2958     0.000588    -0.014620  -0.015595         -0.007163       -0.017204   \n",
       "\n",
       "      EFA_MSCIEAFE  TIP_TIPSBOND  \n",
       "1         0.012923     -0.000748  \n",
       "2        -0.007582     -0.004498  \n",
       "3        -0.021928      0.007393  \n",
       "4         0.007749      0.004187  \n",
       "5        -0.032558      0.005093  \n",
       "...            ...           ...  \n",
       "2954     -0.022777      0.000000  \n",
       "2955      0.004675      0.003176  \n",
       "2956      0.007357      0.003080  \n",
       "2957      0.001927     -0.002738  \n",
       "2958     -0.008507     -0.000943  \n",
       "\n",
       "[2958 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create response variable matrix to be subsequently transformed into y\n",
    "\n",
    "portfolio = data[assets]\n",
    "log_returns = np.log(portfolio/portfolio.shift(1)).dropna()\n",
    "log_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VNQ_VANGREALEST</th>\n",
       "      <th>EMB_USDEMRGBOND</th>\n",
       "      <th>LQD_CORPBOND</th>\n",
       "      <th>MUB_MUNIBOND</th>\n",
       "      <th>SHY_1-3USTR</th>\n",
       "      <th>VIG_VANGDIV</th>\n",
       "      <th>IVV_SP500</th>\n",
       "      <th>EEM_MSCIEMERGING</th>\n",
       "      <th>XLE_ENERGYSPDR</th>\n",
       "      <th>EFA_MSCIEAFE</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB_VOL</th>\n",
       "      <th>LQD_VOL</th>\n",
       "      <th>MUB_VOL</th>\n",
       "      <th>VIG_VOL</th>\n",
       "      <th>IVV_VOL</th>\n",
       "      <th>EEM_VOL</th>\n",
       "      <th>EFA_VOL</th>\n",
       "      <th>XLE_VOL</th>\n",
       "      <th>SHY_VOL</th>\n",
       "      <th>TIP_VOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017507</td>\n",
       "      <td>-0.000754</td>\n",
       "      <td>-0.002072</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>0.013131</td>\n",
       "      <td>0.032254</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234243</td>\n",
       "      <td>0.345803</td>\n",
       "      <td>0.124218</td>\n",
       "      <td>0.506379</td>\n",
       "      <td>1.997616</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.301695</td>\n",
       "      <td>1.721589</td>\n",
       "      <td>0.073689</td>\n",
       "      <td>0.034641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>0.011717</td>\n",
       "      <td>-0.004173</td>\n",
       "      <td>-0.007582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206426</td>\n",
       "      <td>0.342953</td>\n",
       "      <td>0.109681</td>\n",
       "      <td>0.364033</td>\n",
       "      <td>1.117511</td>\n",
       "      <td>0.986725</td>\n",
       "      <td>0.128841</td>\n",
       "      <td>0.637754</td>\n",
       "      <td>0.044497</td>\n",
       "      <td>0.228210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000174</td>\n",
       "      <td>-0.003646</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>-0.014002</td>\n",
       "      <td>-0.012183</td>\n",
       "      <td>-0.028531</td>\n",
       "      <td>-0.012227</td>\n",
       "      <td>-0.021928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162948</td>\n",
       "      <td>0.319982</td>\n",
       "      <td>0.105214</td>\n",
       "      <td>0.394360</td>\n",
       "      <td>1.159634</td>\n",
       "      <td>0.886779</td>\n",
       "      <td>0.290207</td>\n",
       "      <td>0.671141</td>\n",
       "      <td>0.115845</td>\n",
       "      <td>0.287785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.004192</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>-0.004140</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.014602</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>0.007749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156563</td>\n",
       "      <td>0.286197</td>\n",
       "      <td>0.266496</td>\n",
       "      <td>0.358497</td>\n",
       "      <td>1.143866</td>\n",
       "      <td>0.835776</td>\n",
       "      <td>0.302704</td>\n",
       "      <td>0.642441</td>\n",
       "      <td>0.128374</td>\n",
       "      <td>0.452968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.020523</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>-0.018049</td>\n",
       "      <td>-0.025074</td>\n",
       "      <td>-0.046287</td>\n",
       "      <td>-0.042255</td>\n",
       "      <td>-0.032558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191924</td>\n",
       "      <td>0.368284</td>\n",
       "      <td>0.472737</td>\n",
       "      <td>0.516701</td>\n",
       "      <td>1.517778</td>\n",
       "      <td>1.132523</td>\n",
       "      <td>0.545225</td>\n",
       "      <td>1.298218</td>\n",
       "      <td>0.154045</td>\n",
       "      <td>0.688876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>-0.004231</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>-0.015283</td>\n",
       "      <td>-0.018066</td>\n",
       "      <td>-0.007669</td>\n",
       "      <td>-0.024861</td>\n",
       "      <td>-0.022777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507070</td>\n",
       "      <td>0.183439</td>\n",
       "      <td>0.079183</td>\n",
       "      <td>1.388910</td>\n",
       "      <td>3.723606</td>\n",
       "      <td>0.336348</td>\n",
       "      <td>0.355992</td>\n",
       "      <td>1.403093</td>\n",
       "      <td>0.052249</td>\n",
       "      <td>0.066858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.012830</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448687</td>\n",
       "      <td>0.258882</td>\n",
       "      <td>0.157575</td>\n",
       "      <td>1.382292</td>\n",
       "      <td>3.616485</td>\n",
       "      <td>0.232056</td>\n",
       "      <td>0.379803</td>\n",
       "      <td>1.379554</td>\n",
       "      <td>0.112472</td>\n",
       "      <td>0.190971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>0.013426</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650769</td>\n",
       "      <td>0.420868</td>\n",
       "      <td>0.189473</td>\n",
       "      <td>1.318283</td>\n",
       "      <td>3.465087</td>\n",
       "      <td>0.277993</td>\n",
       "      <td>0.350471</td>\n",
       "      <td>1.049843</td>\n",
       "      <td>0.125579</td>\n",
       "      <td>0.332310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>-0.002143</td>\n",
       "      <td>-0.005634</td>\n",
       "      <td>-0.005080</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>-0.005502</td>\n",
       "      <td>-0.004503</td>\n",
       "      <td>-0.008333</td>\n",
       "      <td>-0.008928</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642051</td>\n",
       "      <td>0.415175</td>\n",
       "      <td>0.187563</td>\n",
       "      <td>0.907981</td>\n",
       "      <td>2.591067</td>\n",
       "      <td>0.260615</td>\n",
       "      <td>0.227662</td>\n",
       "      <td>0.535416</td>\n",
       "      <td>0.114761</td>\n",
       "      <td>0.308982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>-0.005270</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>-0.000862</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>-0.014620</td>\n",
       "      <td>-0.015595</td>\n",
       "      <td>-0.007163</td>\n",
       "      <td>-0.017204</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555761</td>\n",
       "      <td>0.380039</td>\n",
       "      <td>0.174413</td>\n",
       "      <td>1.021802</td>\n",
       "      <td>2.795196</td>\n",
       "      <td>0.295973</td>\n",
       "      <td>0.147241</td>\n",
       "      <td>0.573699</td>\n",
       "      <td>0.073959</td>\n",
       "      <td>0.261094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2958 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VNQ_VANGREALEST  EMB_USDEMRGBOND  LQD_CORPBOND  MUB_MUNIBOND  \\\n",
       "1            0.017507        -0.000754     -0.002072      0.002550   \n",
       "2            0.015289         0.000881     -0.002946     -0.001470   \n",
       "3            0.000174        -0.003646      0.007275      0.001274   \n",
       "4           -0.004192         0.003451     -0.004140      0.004496   \n",
       "5           -0.020523         0.001662      0.005359      0.005446   \n",
       "...               ...              ...           ...           ...   \n",
       "2954        -0.004231        -0.000178     -0.000393      0.001754   \n",
       "2955         0.009630         0.004793      0.003922      0.002101   \n",
       "2956         0.006012         0.008728      0.004140      0.000000   \n",
       "2957        -0.002143        -0.005634     -0.005080     -0.000787   \n",
       "2958        -0.005270        -0.000972     -0.000862      0.002883   \n",
       "\n",
       "      SHY_1-3USTR  VIG_VANGDIV  IVV_SP500  EEM_MSCIEMERGING  XLE_ENERGYSPDR  \\\n",
       "1       -0.000484     0.008526   0.013131          0.032254        0.013098   \n",
       "2        0.000000     0.008820   0.006994          0.011717       -0.004173   \n",
       "3        0.002780    -0.014002  -0.012183         -0.028531       -0.012227   \n",
       "4        0.000362     0.006104   0.010139          0.014602        0.019647   \n",
       "5        0.000844    -0.018049  -0.025074         -0.046287       -0.042255   \n",
       "...           ...          ...        ...               ...             ...   \n",
       "2954     0.001061    -0.015283  -0.018066         -0.007669       -0.024861   \n",
       "2955     0.002119     0.005662   0.008287          0.012830        0.010756   \n",
       "2956    -0.000118     0.013426   0.013536          0.004403        0.006294   \n",
       "2957    -0.001059    -0.005502  -0.004503         -0.008333       -0.008928   \n",
       "2958     0.000588    -0.014620  -0.015595         -0.007163       -0.017204   \n",
       "\n",
       "      EFA_MSCIEAFE  ...   EMB_VOL   LQD_VOL   MUB_VOL   VIG_VOL   IVV_VOL  \\\n",
       "1         0.012923  ...  0.234243  0.345803  0.124218  0.506379  1.997616   \n",
       "2        -0.007582  ...  0.206426  0.342953  0.109681  0.364033  1.117511   \n",
       "3        -0.021928  ...  0.162948  0.319982  0.105214  0.394360  1.159634   \n",
       "4         0.007749  ...  0.156563  0.286197  0.266496  0.358497  1.143866   \n",
       "5        -0.032558  ...  0.191924  0.368284  0.472737  0.516701  1.517778   \n",
       "...            ...  ...       ...       ...       ...       ...       ...   \n",
       "2954     -0.022777  ...  0.507070  0.183439  0.079183  1.388910  3.723606   \n",
       "2955      0.004675  ...  0.448687  0.258882  0.157575  1.382292  3.616485   \n",
       "2956      0.007357  ...  0.650769  0.420868  0.189473  1.318283  3.465087   \n",
       "2957      0.001927  ...  0.642051  0.415175  0.187563  0.907981  2.591067   \n",
       "2958     -0.008507  ...  0.555761  0.380039  0.174413  1.021802  2.795196   \n",
       "\n",
       "       EEM_VOL   EFA_VOL   XLE_VOL   SHY_VOL   TIP_VOL  \n",
       "1     0.789580  0.301695  1.721589  0.073689  0.034641  \n",
       "2     0.986725  0.128841  0.637754  0.044497  0.228210  \n",
       "3     0.886779  0.290207  0.671141  0.115845  0.287785  \n",
       "4     0.835776  0.302704  0.642441  0.128374  0.452968  \n",
       "5     1.132523  0.545225  1.298218  0.154045  0.688876  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "2954  0.336348  0.355992  1.403093  0.052249  0.066858  \n",
       "2955  0.232056  0.379803  1.379554  0.112472  0.190971  \n",
       "2956  0.277993  0.350471  1.049843  0.125579  0.332310  \n",
       "2957  0.260615  0.227662  0.535416  0.114761  0.308982  \n",
       "2958  0.295973  0.147241  0.573699  0.073959  0.261094  \n",
       "\n",
       "[2958 rows x 42 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features matrix to be subsequently transformed into X\n",
    "\n",
    "# Log returns of assets\n",
    "asset_features = np.log(data[assets]/data[assets].shift(1))\n",
    "\n",
    "# Scaled macroeconomic factors\n",
    "scale = StandardScaler()\n",
    "econ_features = pd.DataFrame(scale.fit_transform(data[econ]), columns = data[econ].columns)\n",
    "\n",
    "# Log returns of financial instruments\n",
    "finstruments_features = np.log(data[finstruments]/data[finstruments].shift(1))\n",
    "\n",
    "features = pd.concat([asset_features, econ_features, finstruments_features, \n",
    "                     data[shock], data[asset_vols]], axis = 1).dropna()\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition:\n",
    "\n",
    "batch_size = 5\n",
    "n_batches = math.floor(features.shape[0] / batch_size) # number of batches in an epoch\n",
    "n_timesteps = 10 # length of series used for prediction (i.e. how many days we're predict off of)\n",
    "n_features = features.shape[1] # number of features used for prediction\n",
    "n_predicted_vars = log_returns.shape[1] # number of asset values being predicted\n",
    "n_epochs = 10\n",
    "look_ahead_time = 1 # number of days in advance we will predict\n",
    "validation_split = 0.1\n",
    "checkpoint_dir = \"model_checkpoints\"\n",
    "\n",
    "burn_in_length = 200\n",
    "burn_in_epochs = 50\n",
    "\n",
    "delta = np.array([1.5])\n",
    "min_weight = np.array([0.01])\n",
    "vol_window = 10\n",
    "\n",
    "daily_portfolio_weights = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window:\n",
    "            \n",
    "def sliding_window(features, log_returns, end_index, n_timesteps, look_ahead_time):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in features matrix and response var (i.e. log_returns) matrix\n",
    "    RETURNS: X and y matrices for training\n",
    "    \n",
    "    end_index: the most recent time instance used for prediction\n",
    "    n_timesteps: length of series used for prediction\n",
    "    look_ahead_time: how many days ahead we are predicting\n",
    "    \"\"\"\n",
    "    \n",
    "    # start index is derived from end_index - n_timesteps\n",
    "    # X slices up to but does not include end_index\n",
    "    X = np.array(features.iloc[(end_index-n_timesteps):end_index, :])                              \n",
    "    \n",
    "    # y includes end_index and slices up to but does not include end_index + look_ahead_time\n",
    "    # thus, if look_ahead_time = 1, y will only include one day for prediction\n",
    "    y = np.array(log_returns.iloc[end_index+look_ahead_time-1, :]) # currently can only make predictions of a single time step\n",
    "    \n",
    "    # return (X:[n_timesteps,n_features], y:[look_ahead_time, n_assets])\n",
    "    return X, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_epoch(features, log_returns, n_timesteps, look_ahead_time):\n",
    "    \n",
    "    # begin with empty arrays to which we will append \n",
    "    X = np.array([]) \n",
    "    y = np.array([])\n",
    "    \n",
    "    window_count = 0\n",
    "    \n",
    "    for i in range(len(features)-n_timesteps):\n",
    "        \n",
    "        end_index = i + n_timesteps\n",
    "        \n",
    "        # pull out one window\n",
    "        X_one, y_one = sliding_window(features, log_returns, end_index, n_timesteps, look_ahead_time)\n",
    "        \n",
    "        ### append sliding windows ###\n",
    "        # append X_one:[n_timesteps,n_features] to batch ndarray X\n",
    "        X = np.append(X, X_one)\n",
    "        # append y_one:[look_ahead_time, n_assets] to batch ndarray y\n",
    "        y = np.append(y, y_one)\n",
    "        \n",
    "        # count the number of windows (i.e. training instances)\n",
    "        window_count += 1\n",
    "     \n",
    "    \n",
    "    # reshape training vectors given window_count\n",
    "    X = X.reshape(window_count, n_timesteps, features.shape[1])    \n",
    "    y = y.reshape(window_count, log_returns.shape[1])\n",
    "        \n",
    "    return X, y\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 10, 42)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 11)                2376      \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 11)                132       \n",
      "=================================================================\n",
      "Total params: 2,508\n",
      "Trainable params: 2,508\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model:\n",
    "\n",
    "sliding_window_input = tf.keras.layers.Input(shape=(n_timesteps, n_features,), \n",
    "                                             name = \"input_layer\")\n",
    "lstm_out = tf.keras.layers.LSTM(n_predicted_vars, \n",
    "                                activation='tanh', recurrent_activation='sigmoid',\n",
    "                                dropout=0.2, stateful=False,\n",
    "                                name = \"lstm\")(sliding_window_input)\n",
    "dense_out = tf.keras.layers.Dense(n_predicted_vars, \n",
    "                                  activation='relu', name = \"dense_layer\")(lstm_out)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=sliding_window_input, outputs=dense_out)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), \n",
    "              loss='mse')    \n",
    "model.summary()\n",
    "\n",
    "checkpoints = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir + \"/saved_model.hdf5\", verbose=1, \n",
    "                                                     save_best_only=True, \n",
    "                                                     mode='auto', \n",
    "                                                     save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171 samples, validate on 19 samples\n",
      "Epoch 1/50\n",
      "125/171 [====================>.........] - ETA: 0s - loss: 0.0334\n",
      "Epoch 00001: val_loss improved from inf to 0.05262, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 2s 9ms/sample - loss: 0.0329 - val_loss: 0.0526\n",
      "Epoch 2/50\n",
      "130/171 [=====================>........] - ETA: 0s - loss: 0.0323\n",
      "Epoch 00002: val_loss improved from 0.05262 to 0.05159, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 977us/sample - loss: 0.0316 - val_loss: 0.0516\n",
      "Epoch 3/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0318\n",
      "Epoch 00003: val_loss improved from 0.05159 to 0.05057, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 925us/sample - loss: 0.0321 - val_loss: 0.0506\n",
      "Epoch 4/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0290\n",
      "Epoch 00004: val_loss improved from 0.05057 to 0.04962, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 909us/sample - loss: 0.0294 - val_loss: 0.0496\n",
      "Epoch 5/50\n",
      "140/171 [=======================>......] - ETA: 0s - loss: 0.0287\n",
      "Epoch 00005: val_loss improved from 0.04962 to 0.04863, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 926us/sample - loss: 0.0289 - val_loss: 0.0486\n",
      "Epoch 6/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0287\n",
      "Epoch 00006: val_loss improved from 0.04863 to 0.04771, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 904us/sample - loss: 0.0287 - val_loss: 0.0477\n",
      "Epoch 7/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0272\n",
      "Epoch 00007: val_loss improved from 0.04771 to 0.04680, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 886us/sample - loss: 0.0272 - val_loss: 0.0468\n",
      "Epoch 8/50\n",
      "135/171 [======================>.......] - ETA: 0s - loss: 0.0265\n",
      "Epoch 00008: val_loss improved from 0.04680 to 0.04601, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 938us/sample - loss: 0.0263 - val_loss: 0.0460\n",
      "Epoch 9/50\n",
      "140/171 [=======================>......] - ETA: 0s - loss: 0.0259\n",
      "Epoch 00009: val_loss improved from 0.04601 to 0.04520, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 902us/sample - loss: 0.0255 - val_loss: 0.0452\n",
      "Epoch 10/50\n",
      "140/171 [=======================>......] - ETA: 0s - loss: 0.0243\n",
      "Epoch 00010: val_loss improved from 0.04520 to 0.04444, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 897us/sample - loss: 0.0246 - val_loss: 0.0444\n",
      "Epoch 11/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0253\n",
      "Epoch 00011: val_loss improved from 0.04444 to 0.04364, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 866us/sample - loss: 0.0248 - val_loss: 0.0436\n",
      "Epoch 12/50\n",
      "135/171 [======================>.......] - ETA: 0s - loss: 0.0247\n",
      "Epoch 00012: val_loss improved from 0.04364 to 0.04291, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 897us/sample - loss: 0.0239 - val_loss: 0.0429\n",
      "Epoch 13/50\n",
      "140/171 [=======================>......] - ETA: 0s - loss: 0.0220\n",
      "Epoch 00013: val_loss improved from 0.04291 to 0.04220, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 892us/sample - loss: 0.0227 - val_loss: 0.0422\n",
      "Epoch 14/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0216\n",
      "Epoch 00014: val_loss improved from 0.04220 to 0.04152, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 877us/sample - loss: 0.0213 - val_loss: 0.0415\n",
      "Epoch 15/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0206\n",
      "Epoch 00015: val_loss improved from 0.04152 to 0.04085, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 871us/sample - loss: 0.0211 - val_loss: 0.0409\n",
      "Epoch 16/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0212\n",
      "Epoch 00016: val_loss improved from 0.04085 to 0.04016, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 875us/sample - loss: 0.0211 - val_loss: 0.0402\n",
      "Epoch 17/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0205\n",
      "Epoch 00017: val_loss improved from 0.04016 to 0.03954, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 875us/sample - loss: 0.0203 - val_loss: 0.0395\n",
      "Epoch 18/50\n",
      "140/171 [=======================>......] - ETA: 0s - loss: 0.0190\n",
      "Epoch 00018: val_loss improved from 0.03954 to 0.03899, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 894us/sample - loss: 0.0189 - val_loss: 0.0390\n",
      "Epoch 19/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 00019: val_loss improved from 0.03899 to 0.03845, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 883us/sample - loss: 0.0183 - val_loss: 0.0385\n",
      "Epoch 20/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0179\n",
      "Epoch 00020: val_loss improved from 0.03845 to 0.03792, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 873us/sample - loss: 0.0182 - val_loss: 0.0379\n",
      "Epoch 21/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0179\n",
      "Epoch 00021: val_loss improved from 0.03792 to 0.03734, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 851us/sample - loss: 0.0178 - val_loss: 0.0373\n",
      "Epoch 22/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0176\n",
      "Epoch 00022: val_loss improved from 0.03734 to 0.03680, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 858us/sample - loss: 0.0174 - val_loss: 0.0368\n",
      "Epoch 23/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0171\n",
      "Epoch 00023: val_loss improved from 0.03680 to 0.03630, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 874us/sample - loss: 0.0171 - val_loss: 0.0363\n",
      "Epoch 24/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0159\n",
      "Epoch 00024: val_loss improved from 0.03630 to 0.03577, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 873us/sample - loss: 0.0157 - val_loss: 0.0358\n",
      "Epoch 25/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00025: val_loss improved from 0.03577 to 0.03535, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 870us/sample - loss: 0.0158 - val_loss: 0.0353\n",
      "Epoch 26/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00026: val_loss improved from 0.03535 to 0.03491, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 887us/sample - loss: 0.0157 - val_loss: 0.0349\n",
      "Epoch 27/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00027: val_loss improved from 0.03491 to 0.03441, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 902us/sample - loss: 0.0147 - val_loss: 0.0344\n",
      "Epoch 28/50\n",
      "130/171 [=====================>........] - ETA: 0s - loss: 0.0131\n",
      "Epoch 00028: val_loss improved from 0.03441 to 0.03401, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 957us/sample - loss: 0.0141 - val_loss: 0.0340\n",
      "Epoch 29/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00029: val_loss improved from 0.03401 to 0.03358, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 859us/sample - loss: 0.0137 - val_loss: 0.0336\n",
      "Epoch 30/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0130\n",
      "Epoch 00030: val_loss improved from 0.03358 to 0.03321, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 863us/sample - loss: 0.0136 - val_loss: 0.0332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0133\n",
      "Epoch 00031: val_loss improved from 0.03321 to 0.03281, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 827us/sample - loss: 0.0133 - val_loss: 0.0328\n",
      "Epoch 32/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0126\n",
      "Epoch 00032: val_loss improved from 0.03281 to 0.03246, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 834us/sample - loss: 0.0123 - val_loss: 0.0325\n",
      "Epoch 33/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0128\n",
      "Epoch 00033: val_loss improved from 0.03246 to 0.03213, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 838us/sample - loss: 0.0128 - val_loss: 0.0321\n",
      "Epoch 34/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00034: val_loss improved from 0.03213 to 0.03179, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 833us/sample - loss: 0.0121 - val_loss: 0.0318\n",
      "Epoch 35/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0114\n",
      "Epoch 00035: val_loss improved from 0.03179 to 0.03150, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 829us/sample - loss: 0.0116 - val_loss: 0.0315\n",
      "Epoch 36/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0105\n",
      "Epoch 00036: val_loss improved from 0.03150 to 0.03113, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 826us/sample - loss: 0.0106 - val_loss: 0.0311\n",
      "Epoch 37/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0114\n",
      "Epoch 00037: val_loss improved from 0.03113 to 0.03078, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 845us/sample - loss: 0.0113 - val_loss: 0.0308\n",
      "Epoch 38/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0109\n",
      "Epoch 00038: val_loss improved from 0.03078 to 0.03048, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 852us/sample - loss: 0.0108 - val_loss: 0.0305\n",
      "Epoch 39/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0104\n",
      "Epoch 00039: val_loss improved from 0.03048 to 0.03017, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 823us/sample - loss: 0.0102 - val_loss: 0.0302\n",
      "Epoch 40/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0104\n",
      "Epoch 00040: val_loss improved from 0.03017 to 0.02989, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 845us/sample - loss: 0.0103 - val_loss: 0.0299\n",
      "Epoch 41/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0097\n",
      "Epoch 00041: val_loss improved from 0.02989 to 0.02964, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 846us/sample - loss: 0.0094 - val_loss: 0.0296\n",
      "Epoch 42/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00042: val_loss improved from 0.02964 to 0.02933, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 832us/sample - loss: 0.0109 - val_loss: 0.0293\n",
      "Epoch 43/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0095\n",
      "Epoch 00043: val_loss improved from 0.02933 to 0.02904, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 824us/sample - loss: 0.0096 - val_loss: 0.0290\n",
      "Epoch 44/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0093\n",
      "Epoch 00044: val_loss improved from 0.02904 to 0.02876, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 846us/sample - loss: 0.0091 - val_loss: 0.0288\n",
      "Epoch 45/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00045: val_loss improved from 0.02876 to 0.02852, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 830us/sample - loss: 0.0090 - val_loss: 0.0285\n",
      "Epoch 46/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0084\n",
      "Epoch 00046: val_loss improved from 0.02852 to 0.02824, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 829us/sample - loss: 0.0087 - val_loss: 0.0282\n",
      "Epoch 47/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0079\n",
      "Epoch 00047: val_loss improved from 0.02824 to 0.02803, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 867us/sample - loss: 0.0080 - val_loss: 0.0280\n",
      "Epoch 48/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0090\n",
      "Epoch 00048: val_loss improved from 0.02803 to 0.02781, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 846us/sample - loss: 0.0089 - val_loss: 0.0278\n",
      "Epoch 49/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0085\n",
      "Epoch 00049: val_loss improved from 0.02781 to 0.02754, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 846us/sample - loss: 0.0084 - val_loss: 0.0275\n",
      "Epoch 50/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0079\n",
      "Epoch 00050: val_loss improved from 0.02754 to 0.02727, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 826us/sample - loss: 0.0077 - val_loss: 0.0273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a5bc11590>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# burn in period\n",
    "\n",
    "training_features = features.iloc[0:burn_in_length,:]\n",
    "training_response = log_returns.iloc[0:burn_in_length,:]\n",
    "\n",
    "X, y = generate_epoch(training_features, training_response, n_timesteps, look_ahead_time)\n",
    "\n",
    "model.fit(X, y,\n",
    "          validation_split = validation_split,\n",
    "          epochs = burn_in_epochs,\n",
    "          batch_size = batch_size,\n",
    "          callbacks = [checkpoints])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2758 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171 samples, validate on 19 samples\n",
      "Epoch 1/50\n",
      "120/171 [====================>.........] - ETA: 0s - loss: 0.0108\n",
      "Epoch 00001: val_loss improved from 0.02727 to 0.02696, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 1s 5ms/sample - loss: 0.0100 - val_loss: 0.0270\n",
      "Epoch 2/50\n",
      "135/171 [======================>.......] - ETA: 0s - loss: 0.0100\n",
      "Epoch 00002: val_loss improved from 0.02696 to 0.02653, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 948us/sample - loss: 0.0098 - val_loss: 0.0265\n",
      "Epoch 3/50\n",
      "140/171 [=======================>......] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00003: val_loss improved from 0.02653 to 0.02613, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 940us/sample - loss: 0.0097 - val_loss: 0.0261\n",
      "Epoch 4/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00004: val_loss improved from 0.02613 to 0.02572, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 910us/sample - loss: 0.0102 - val_loss: 0.0257\n",
      "Epoch 5/50\n",
      "135/171 [======================>.......] - ETA: 0s - loss: 0.0078\n",
      "Epoch 00005: val_loss improved from 0.02572 to 0.02532, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 945us/sample - loss: 0.0086 - val_loss: 0.0253\n",
      "Epoch 6/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00006: val_loss improved from 0.02532 to 0.02499, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 908us/sample - loss: 0.0091 - val_loss: 0.0250\n",
      "Epoch 7/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0086\n",
      "Epoch 00007: val_loss improved from 0.02499 to 0.02471, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 848us/sample - loss: 0.0089 - val_loss: 0.0247\n",
      "Epoch 8/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00008: val_loss improved from 0.02471 to 0.02438, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 843us/sample - loss: 0.0094 - val_loss: 0.0244\n",
      "Epoch 9/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00009: val_loss improved from 0.02438 to 0.02405, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 895us/sample - loss: 0.0091 - val_loss: 0.0240\n",
      "Epoch 10/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0097\n",
      "Epoch 00010: val_loss improved from 0.02405 to 0.02377, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 882us/sample - loss: 0.0091 - val_loss: 0.0238\n",
      "Epoch 11/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0084\n",
      "Epoch 00011: val_loss improved from 0.02377 to 0.02349, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 831us/sample - loss: 0.0091 - val_loss: 0.0235\n",
      "Epoch 12/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0083\n",
      "Epoch 00012: val_loss improved from 0.02349 to 0.02324, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 875us/sample - loss: 0.0081 - val_loss: 0.0232\n",
      "Epoch 13/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0078\n",
      "Epoch 00013: val_loss improved from 0.02324 to 0.02301, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 866us/sample - loss: 0.0084 - val_loss: 0.0230\n",
      "Epoch 14/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0083\n",
      "Epoch 00014: val_loss improved from 0.02301 to 0.02271, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 856us/sample - loss: 0.0081 - val_loss: 0.0227\n",
      "Epoch 15/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0081\n",
      "Epoch 00015: val_loss improved from 0.02271 to 0.02241, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 880us/sample - loss: 0.0078 - val_loss: 0.0224\n",
      "Epoch 16/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0066\n",
      "Epoch 00016: val_loss improved from 0.02241 to 0.02217, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 880us/sample - loss: 0.0077 - val_loss: 0.0222\n",
      "Epoch 17/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0080\n",
      "Epoch 00017: val_loss improved from 0.02217 to 0.02192, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 889us/sample - loss: 0.0077 - val_loss: 0.0219\n",
      "Epoch 18/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0080\n",
      "Epoch 00018: val_loss improved from 0.02192 to 0.02172, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 858us/sample - loss: 0.0076 - val_loss: 0.0217\n",
      "Epoch 19/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0077\n",
      "Epoch 00019: val_loss improved from 0.02172 to 0.02154, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 879us/sample - loss: 0.0074 - val_loss: 0.0215\n",
      "Epoch 20/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0073\n",
      "Epoch 00020: val_loss improved from 0.02154 to 0.02136, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 847us/sample - loss: 0.0072 - val_loss: 0.0214\n",
      "Epoch 21/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00021: val_loss improved from 0.02136 to 0.02116, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 875us/sample - loss: 0.0068 - val_loss: 0.0212\n",
      "Epoch 22/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0075\n",
      "Epoch 00022: val_loss improved from 0.02116 to 0.02090, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 874us/sample - loss: 0.0071 - val_loss: 0.0209\n",
      "Epoch 23/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0071\n",
      "Epoch 00023: val_loss improved from 0.02090 to 0.02065, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 900us/sample - loss: 0.0067 - val_loss: 0.0207\n",
      "Epoch 24/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0067\n",
      "Epoch 00024: val_loss improved from 0.02065 to 0.02044, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 864us/sample - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 25/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0068\n",
      "Epoch 00025: val_loss improved from 0.02044 to 0.02014, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 847us/sample - loss: 0.0066 - val_loss: 0.0201\n",
      "Epoch 26/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0069\n",
      "Epoch 00026: val_loss improved from 0.02014 to 0.01987, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 894us/sample - loss: 0.0071 - val_loss: 0.0199\n",
      "Epoch 27/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00027: val_loss improved from 0.01987 to 0.01960, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 865us/sample - loss: 0.0065 - val_loss: 0.0196\n",
      "Epoch 28/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0058\n",
      "Epoch 00028: val_loss improved from 0.01960 to 0.01929, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 830us/sample - loss: 0.0062 - val_loss: 0.0193\n",
      "Epoch 29/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0058\n",
      "Epoch 00029: val_loss improved from 0.01929 to 0.01909, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 834us/sample - loss: 0.0058 - val_loss: 0.0191\n",
      "Epoch 30/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0069\n",
      "Epoch 00030: val_loss improved from 0.01909 to 0.01892, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 857us/sample - loss: 0.0066 - val_loss: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0061\n",
      "Epoch 00031: val_loss improved from 0.01892 to 0.01873, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 816us/sample - loss: 0.0060 - val_loss: 0.0187\n",
      "Epoch 32/50\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00032: val_loss improved from 0.01873 to 0.01851, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 812us/sample - loss: 0.0064 - val_loss: 0.0185\n",
      "Epoch 33/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0066\n",
      "Epoch 00033: val_loss improved from 0.01851 to 0.01826, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 812us/sample - loss: 0.0065 - val_loss: 0.0183\n",
      "Epoch 34/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0053\n",
      "Epoch 00034: val_loss improved from 0.01826 to 0.01807, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 828us/sample - loss: 0.0052 - val_loss: 0.0181\n",
      "Epoch 35/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0058\n",
      "Epoch 00035: val_loss improved from 0.01807 to 0.01786, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 816us/sample - loss: 0.0057 - val_loss: 0.0179\n",
      "Epoch 36/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0054\n",
      "Epoch 00036: val_loss improved from 0.01786 to 0.01769, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 827us/sample - loss: 0.0054 - val_loss: 0.0177\n",
      "Epoch 37/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00037: val_loss improved from 0.01769 to 0.01750, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 841us/sample - loss: 0.0060 - val_loss: 0.0175\n",
      "Epoch 38/50\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 0.0058\n",
      "Epoch 00038: val_loss improved from 0.01750 to 0.01731, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 802us/sample - loss: 0.0057 - val_loss: 0.0173\n",
      "Epoch 39/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0055\n",
      "Epoch 00039: val_loss improved from 0.01731 to 0.01711, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 829us/sample - loss: 0.0057 - val_loss: 0.0171\n",
      "Epoch 40/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0054\n",
      "Epoch 00040: val_loss improved from 0.01711 to 0.01688, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 822us/sample - loss: 0.0053 - val_loss: 0.0169\n",
      "Epoch 41/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0050\n",
      "Epoch 00041: val_loss improved from 0.01688 to 0.01672, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 820us/sample - loss: 0.0050 - val_loss: 0.0167\n",
      "Epoch 42/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00042: val_loss improved from 0.01672 to 0.01652, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 812us/sample - loss: 0.0051 - val_loss: 0.0165\n",
      "Epoch 43/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00043: val_loss improved from 0.01652 to 0.01630, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 827us/sample - loss: 0.0060 - val_loss: 0.0163\n",
      "Epoch 44/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00044: val_loss improved from 0.01630 to 0.01606, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 824us/sample - loss: 0.0047 - val_loss: 0.0161\n",
      "Epoch 45/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00045: val_loss improved from 0.01606 to 0.01585, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 831us/sample - loss: 0.0050 - val_loss: 0.0159\n",
      "Epoch 46/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00046: val_loss improved from 0.01585 to 0.01564, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 822us/sample - loss: 0.0044 - val_loss: 0.0156\n",
      "Epoch 47/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00047: val_loss improved from 0.01564 to 0.01553, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 844us/sample - loss: 0.0044 - val_loss: 0.0155\n",
      "Epoch 48/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00048: val_loss improved from 0.01553 to 0.01537, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 829us/sample - loss: 0.0047 - val_loss: 0.0154\n",
      "Epoch 49/50\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00049: val_loss improved from 0.01537 to 0.01520, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 811us/sample - loss: 0.0044 - val_loss: 0.0152\n",
      "Epoch 50/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00050: val_loss improved from 0.01520 to 0.01501, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 835us/sample - loss: 0.0047 - val_loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisolen/anaconda3/lib/python3.7/site-packages/julia/core.py:689: FutureWarning: Accessing `Julia().<name>` to obtain Julia objects is deprecated.  Use `from julia import Main; Main.<name>` or `jl = Julia(); jl.eval('<name>')`.\n",
      "  FutureWarning,\n",
      "\r",
      "  0%|          | 1/2758 [00:09<7:12:46,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96.9 ms, sys: 3.76 ms, total: 101 ms\n",
      "Wall time: 112 ms\n",
      "Train on 171 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "135/171 [======================>.......] - ETA: 0s - loss: 0.0040\n",
      "Epoch 00001: val_loss improved from 0.01501 to 0.01455, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 1s 5ms/sample - loss: 0.0046 - val_loss: 0.0146\n",
      "Epoch 2/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00002: val_loss improved from 0.01455 to 0.01440, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 888us/sample - loss: 0.0043 - val_loss: 0.0144\n",
      "Epoch 3/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00003: val_loss improved from 0.01440 to 0.01425, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 895us/sample - loss: 0.0048 - val_loss: 0.0142\n",
      "Epoch 4/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00004: val_loss improved from 0.01425 to 0.01406, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 852us/sample - loss: 0.0044 - val_loss: 0.0141\n",
      "Epoch 5/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00005: val_loss improved from 0.01406 to 0.01392, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 838us/sample - loss: 0.0036 - val_loss: 0.0139\n",
      "Epoch 6/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00006: val_loss improved from 0.01392 to 0.01379, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 858us/sample - loss: 0.0041 - val_loss: 0.0138\n",
      "Epoch 7/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00007: val_loss improved from 0.01379 to 0.01365, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 891us/sample - loss: 0.0041 - val_loss: 0.0136\n",
      "Epoch 8/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00008: val_loss improved from 0.01365 to 0.01347, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 882us/sample - loss: 0.0039 - val_loss: 0.0135\n",
      "Epoch 9/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00009: val_loss improved from 0.01347 to 0.01335, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 862us/sample - loss: 0.0038 - val_loss: 0.0134\n",
      "Epoch 10/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00010: val_loss improved from 0.01335 to 0.01320, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 862us/sample - loss: 0.0041 - val_loss: 0.0132\n",
      "Epoch 11/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0040\n",
      "Epoch 00011: val_loss improved from 0.01320 to 0.01307, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 885us/sample - loss: 0.0037 - val_loss: 0.0131\n",
      "Epoch 12/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0040\n",
      "Epoch 00012: val_loss improved from 0.01307 to 0.01290, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 856us/sample - loss: 0.0038 - val_loss: 0.0129\n",
      "Epoch 13/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00013: val_loss improved from 0.01290 to 0.01275, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 845us/sample - loss: 0.0042 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0036\n",
      "Epoch 00014: val_loss improved from 0.01275 to 0.01261, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 851us/sample - loss: 0.0040 - val_loss: 0.0126\n",
      "Epoch 15/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0034   \n",
      "Epoch 00015: val_loss improved from 0.01261 to 0.01247, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 859us/sample - loss: 0.0035 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0036\n",
      "Epoch 00016: val_loss improved from 0.01247 to 0.01237, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 844us/sample - loss: 0.0035 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00017: val_loss improved from 0.01237 to 0.01222, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 856us/sample - loss: 0.0037 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00018: val_loss improved from 0.01222 to 0.01206, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 849us/sample - loss: 0.0033 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00019: val_loss improved from 0.01206 to 0.01194, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 849us/sample - loss: 0.0037 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0040\n",
      "Epoch 00020: val_loss improved from 0.01194 to 0.01179, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 870us/sample - loss: 0.0037 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0029   \n",
      "Epoch 00021: val_loss improved from 0.01179 to 0.01170, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 850us/sample - loss: 0.0031 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "145/171 [========================>.....] - ETA: 0s - loss: 0.0029   \n",
      "Epoch 00022: val_loss improved from 0.01170 to 0.01153, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 880us/sample - loss: 0.0034 - val_loss: 0.0115\n",
      "Epoch 23/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00023: val_loss improved from 0.01153 to 0.01137, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 838us/sample - loss: 0.0031 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00024: val_loss improved from 0.01137 to 0.01123, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 912us/sample - loss: 0.0032 - val_loss: 0.0112\n",
      "Epoch 25/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00025: val_loss improved from 0.01123 to 0.01110, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 854us/sample - loss: 0.0039 - val_loss: 0.0111\n",
      "Epoch 26/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00026: val_loss improved from 0.01110 to 0.01093, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 857us/sample - loss: 0.0036 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0036\n",
      "Epoch 00027: val_loss improved from 0.01093 to 0.01081, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 865us/sample - loss: 0.0034 - val_loss: 0.0108\n",
      "Epoch 28/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00028: val_loss improved from 0.01081 to 0.01069, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 859us/sample - loss: 0.0033 - val_loss: 0.0107\n",
      "Epoch 29/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00029: val_loss improved from 0.01069 to 0.01055, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 854us/sample - loss: 0.0037 - val_loss: 0.0105\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00030: val_loss improved from 0.01055 to 0.01045, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 840us/sample - loss: 0.0031 - val_loss: 0.0105\n",
      "Epoch 31/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00031: val_loss improved from 0.01045 to 0.01033, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 827us/sample - loss: 0.0034 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00032: val_loss improved from 0.01033 to 0.01020, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 860us/sample - loss: 0.0032 - val_loss: 0.0102\n",
      "Epoch 33/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00033: val_loss improved from 0.01020 to 0.01008, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 837us/sample - loss: 0.0035 - val_loss: 0.0101\n",
      "Epoch 34/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00034: val_loss improved from 0.01008 to 0.00994, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 846us/sample - loss: 0.0031 - val_loss: 0.0099\n",
      "Epoch 35/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00035: val_loss improved from 0.00994 to 0.00982, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 858us/sample - loss: 0.0031 - val_loss: 0.0098\n",
      "Epoch 36/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0033\n",
      "Epoch 00036: val_loss improved from 0.00982 to 0.00971, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 860us/sample - loss: 0.0032 - val_loss: 0.0097\n",
      "Epoch 37/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00037: val_loss improved from 0.00971 to 0.00960, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 860us/sample - loss: 0.0032 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0032   \n",
      "Epoch 00038: val_loss improved from 0.00960 to 0.00951, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 851us/sample - loss: 0.0030 - val_loss: 0.0095\n",
      "Epoch 39/50\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00039: val_loss improved from 0.00951 to 0.00939, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 819us/sample - loss: 0.0028 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0029   \n",
      "Epoch 00040: val_loss improved from 0.00939 to 0.00931, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 844us/sample - loss: 0.0028 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00041: val_loss improved from 0.00931 to 0.00922, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 844us/sample - loss: 0.0028 - val_loss: 0.0092\n",
      "Epoch 42/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00042: val_loss improved from 0.00922 to 0.00914, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 853us/sample - loss: 0.0027 - val_loss: 0.0091\n",
      "Epoch 43/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00043: val_loss improved from 0.00914 to 0.00906, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 831us/sample - loss: 0.0026 - val_loss: 0.0091\n",
      "Epoch 44/50\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.0031   \n",
      "Epoch 00044: val_loss improved from 0.00906 to 0.00894, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 835us/sample - loss: 0.0029 - val_loss: 0.0089\n",
      "Epoch 45/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0031   \n",
      "Epoch 00045: val_loss improved from 0.00894 to 0.00884, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 843us/sample - loss: 0.0030 - val_loss: 0.0088\n",
      "Epoch 46/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0033\n",
      "Epoch 00046: val_loss improved from 0.00884 to 0.00874, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 846us/sample - loss: 0.0030 - val_loss: 0.0087\n",
      "Epoch 47/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00047: val_loss improved from 0.00874 to 0.00863, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 840us/sample - loss: 0.0026 - val_loss: 0.0086\n",
      "Epoch 48/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00048: val_loss improved from 0.00863 to 0.00851, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 865us/sample - loss: 0.0032 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "150/171 [=========================>....] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00049: val_loss improved from 0.00851 to 0.00842, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 860us/sample - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 50/50\n",
      "155/171 [==========================>...] - ETA: 0s - loss: 0.0030   \n",
      "Epoch 00050: val_loss improved from 0.00842 to 0.00833, saving model to model_checkpoints/saved_model.hdf5\n",
      "171/171 [==============================] - 0s 836us/sample - loss: 0.0028 - val_loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/2758 [00:18<7:11:42,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 100 ms, sys: 3.86 ms, total: 104 ms\n",
      "Wall time: 128 ms\n",
      "Train on 172 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "135/172 [======================>.......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00001: val_loss did not improve from 0.00833\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.0025 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0026   \n",
      "Epoch 00002: val_loss did not improve from 0.00833\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.0024 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0024\n",
      "Epoch 00003: val_loss did not improve from 0.00833\n",
      "172/172 [==============================] - 0s 783us/sample - loss: 0.0025 - val_loss: 0.0085\n",
      "Epoch 4/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00004: val_loss did not improve from 0.00833\n",
      "172/172 [==============================] - 0s 778us/sample - loss: 0.0022 - val_loss: 0.0084\n",
      "Epoch 5/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0026   \n",
      "Epoch 00005: val_loss improved from 0.00833 to 0.00832, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.0029 - val_loss: 0.0083\n",
      "Epoch 6/50\n",
      "160/172 [==========================>...] - ETA: 0s - loss: 0.0023   \n",
      "Epoch 00006: val_loss improved from 0.00832 to 0.00819, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.0026 - val_loss: 0.0082\n",
      "Epoch 7/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00007: val_loss improved from 0.00819 to 0.00809, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.0029 - val_loss: 0.0081\n",
      "Epoch 8/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00008: val_loss improved from 0.00809 to 0.00798, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.0022 - val_loss: 0.0080\n",
      "Epoch 9/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0025   \n",
      "Epoch 00009: val_loss improved from 0.00798 to 0.00790, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.0024 - val_loss: 0.0079\n",
      "Epoch 10/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00010: val_loss improved from 0.00790 to 0.00782, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.0024 - val_loss: 0.0078\n",
      "Epoch 11/50\n",
      "160/172 [==========================>...] - ETA: 0s - loss: 0.0024   \n",
      "Epoch 00011: val_loss improved from 0.00782 to 0.00774, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.0025 - val_loss: 0.0077\n",
      "Epoch 12/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00012: val_loss improved from 0.00774 to 0.00766, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.0020 - val_loss: 0.0077\n",
      "Epoch 13/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0024   \n",
      "Epoch 00013: val_loss improved from 0.00766 to 0.00758, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.0022 - val_loss: 0.0076\n",
      "Epoch 14/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00014: val_loss improved from 0.00758 to 0.00749, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.0024 - val_loss: 0.0075\n",
      "Epoch 15/50\n",
      "145/172 [========================>.....] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00015: val_loss improved from 0.00749 to 0.00739, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.0023 - val_loss: 0.0074\n",
      "Epoch 16/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0027   \n",
      "Epoch 00016: val_loss improved from 0.00739 to 0.00729, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.0026 - val_loss: 0.0073\n",
      "Epoch 17/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00017: val_loss improved from 0.00729 to 0.00722, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.0017 - val_loss: 0.0072\n",
      "Epoch 18/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0028   \n",
      "Epoch 00018: val_loss improved from 0.00722 to 0.00716, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 19/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0027   \n",
      "Epoch 00019: val_loss improved from 0.00716 to 0.00712, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.0027 - val_loss: 0.0071\n",
      "Epoch 20/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0022   \n",
      "Epoch 00020: val_loss improved from 0.00712 to 0.00702, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.0021 - val_loss: 0.0070\n",
      "Epoch 21/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0026   \n",
      "Epoch 00021: val_loss improved from 0.00702 to 0.00693, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.0024 - val_loss: 0.0069\n",
      "Epoch 22/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00022: val_loss improved from 0.00693 to 0.00686, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.0022 - val_loss: 0.0069\n",
      "Epoch 23/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0020   \n",
      "Epoch 00023: val_loss improved from 0.00686 to 0.00681, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 24/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0023   \n",
      "Epoch 00024: val_loss improved from 0.00681 to 0.00671, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.0022 - val_loss: 0.0067\n",
      "Epoch 25/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00025: val_loss improved from 0.00671 to 0.00665, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 26/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00026: val_loss improved from 0.00665 to 0.00656, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.0026 - val_loss: 0.0066\n",
      "Epoch 27/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00027: val_loss improved from 0.00656 to 0.00648, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 28/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00028: val_loss improved from 0.00648 to 0.00640, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.0025 - val_loss: 0.0064\n",
      "Epoch 29/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0022   \n",
      "Epoch 00029: val_loss improved from 0.00640 to 0.00635, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 30/50\n",
      "160/172 [==========================>...] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00030: val_loss improved from 0.00635 to 0.00629, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.0018 - val_loss: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00031: val_loss improved from 0.00629 to 0.00622, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 32/50\n",
      "160/172 [==========================>...] - ETA: 0s - loss: 0.0022   \n",
      "Epoch 00032: val_loss improved from 0.00622 to 0.00618, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 33/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0021   \n",
      "Epoch 00033: val_loss improved from 0.00618 to 0.00610, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 34/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0027   \n",
      "Epoch 00034: val_loss improved from 0.00610 to 0.00604, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 35/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0022   \n",
      "Epoch 00035: val_loss improved from 0.00604 to 0.00597, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 36/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0023   \n",
      "Epoch 00036: val_loss improved from 0.00597 to 0.00591, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 37/50\n",
      "160/172 [==========================>...] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00037: val_loss improved from 0.00591 to 0.00584, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 38/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00038: val_loss improved from 0.00584 to 0.00577, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 39/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0024   \n",
      "Epoch 00039: val_loss improved from 0.00577 to 0.00570, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 40/50\n",
      "160/172 [==========================>...] - ETA: 0s - loss: 0.0018    \n",
      "Epoch 00040: val_loss improved from 0.00570 to 0.00564, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 41/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0021   \n",
      "Epoch 00041: val_loss improved from 0.00564 to 0.00559, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 42/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00042: val_loss improved from 0.00559 to 0.00554, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 43/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0019   \n",
      "Epoch 00043: val_loss improved from 0.00554 to 0.00548, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 44/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00044: val_loss improved from 0.00548 to 0.00540, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 45/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00045: val_loss improved from 0.00540 to 0.00533, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 46/50\n",
      "160/172 [==========================>...] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00046: val_loss improved from 0.00533 to 0.00528, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 47/50\n",
      "150/172 [=========================>....] - ETA: 0s - loss: 0.0022   \n",
      "Epoch 00047: val_loss improved from 0.00528 to 0.00524, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 48/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00048: val_loss improved from 0.00524 to 0.00519, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 49/50\n",
      "160/172 [==========================>...] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00049: val_loss improved from 0.00519 to 0.00512, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 50/50\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00050: val_loss improved from 0.00512 to 0.00507, saving model to model_checkpoints/saved_model.hdf5\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.0015 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/2758 [00:27<7:07:37,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 92.9 ms, sys: 2.52 ms, total: 95.5 ms\n",
      "Wall time: 95.5 ms\n",
      "Train on 173 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "135/173 [======================>.......] - ETA: 0s - loss: 0.0022   \n",
      "Epoch 00001: val_loss improved from 0.00507 to 0.00494, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 1s 5ms/sample - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 2/50\n",
      "145/173 [========================>.....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00002: val_loss improved from 0.00494 to 0.00487, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 889us/sample - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 3/50\n",
      "145/173 [========================>.....] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00003: val_loss improved from 0.00487 to 0.00480, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 885us/sample - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 4/50\n",
      "150/173 [=========================>....] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00004: val_loss improved from 0.00480 to 0.00475, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 872us/sample - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0019   \n",
      "Epoch 00005: val_loss improved from 0.00475 to 0.00471, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 840us/sample - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 6/50\n",
      "145/173 [========================>.....] - ETA: 0s - loss: 0.0027   \n",
      "Epoch 00006: val_loss improved from 0.00471 to 0.00466, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 864us/sample - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 7/50\n",
      "150/173 [=========================>....] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00007: val_loss improved from 0.00466 to 0.00461, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 861us/sample - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 8/50\n",
      "150/173 [=========================>....] - ETA: 0s - loss: 0.0022   \n",
      "Epoch 00008: val_loss improved from 0.00461 to 0.00455, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 871us/sample - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00009: val_loss improved from 0.00455 to 0.00451, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 843us/sample - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 10/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0018    \n",
      "Epoch 00010: val_loss improved from 0.00451 to 0.00447, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 852us/sample - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 11/50\n",
      "140/173 [=======================>......] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00011: val_loss improved from 0.00447 to 0.00443, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 890us/sample - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 12/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0021   \n",
      "Epoch 00012: val_loss improved from 0.00443 to 0.00438, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 835us/sample - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 13/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00013: val_loss improved from 0.00438 to 0.00434, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 837us/sample - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 14/50\n",
      "150/173 [=========================>....] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00014: val_loss improved from 0.00434 to 0.00431, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 849us/sample - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 15/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00015: val_loss improved from 0.00431 to 0.00429, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 848us/sample - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 16/50\n",
      "150/173 [=========================>....] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00016: val_loss improved from 0.00429 to 0.00425, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 842us/sample - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 17/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00017: val_loss improved from 0.00425 to 0.00421, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 839us/sample - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 18/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00018: val_loss improved from 0.00421 to 0.00417, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 845us/sample - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 19/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0019   \n",
      "Epoch 00019: val_loss improved from 0.00417 to 0.00413, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 820us/sample - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 20/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0021   \n",
      "Epoch 00020: val_loss improved from 0.00413 to 0.00412, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 815us/sample - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 21/50\n",
      "150/173 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00021: val_loss improved from 0.00412 to 0.00408, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 842us/sample - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0019    \n",
      "Epoch 00022: val_loss improved from 0.00408 to 0.00404, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 813us/sample - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 23/50\n",
      "165/173 [===========================>..] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00023: val_loss improved from 0.00404 to 0.00399, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 805us/sample - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 24/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00024: val_loss improved from 0.00399 to 0.00394, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 823us/sample - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 25/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0010   \n",
      "Epoch 00025: val_loss improved from 0.00394 to 0.00392, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 840us/sample - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 26/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00026: val_loss improved from 0.00392 to 0.00389, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 820us/sample - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 27/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00027: val_loss improved from 0.00389 to 0.00387, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 810us/sample - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 28/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00028: val_loss improved from 0.00387 to 0.00384, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 827us/sample - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 29/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00029: val_loss improved from 0.00384 to 0.00382, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 827us/sample - loss: 0.0014 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0021   \n",
      "Epoch 00030: val_loss improved from 0.00382 to 0.00379, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 802us/sample - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 31/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00031: val_loss improved from 0.00379 to 0.00376, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 815us/sample - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 32/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00032: val_loss improved from 0.00376 to 0.00374, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 852us/sample - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 33/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00033: val_loss improved from 0.00374 to 0.00372, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 808us/sample - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 34/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00034: val_loss improved from 0.00372 to 0.00370, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 815us/sample - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 35/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00035: val_loss improved from 0.00370 to 0.00367, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 818us/sample - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 36/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0020    \n",
      "Epoch 00036: val_loss improved from 0.00367 to 0.00364, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 832us/sample - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 37/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00037: val_loss improved from 0.00364 to 0.00361, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 812us/sample - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00038: val_loss improved from 0.00361 to 0.00358, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 824us/sample - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0020   \n",
      "Epoch 00039: val_loss improved from 0.00358 to 0.00355, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 829us/sample - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 40/50\n",
      "150/173 [=========================>....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00040: val_loss improved from 0.00355 to 0.00351, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 859us/sample - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 41/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00041: val_loss improved from 0.00351 to 0.00349, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 835us/sample - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 42/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00042: val_loss improved from 0.00349 to 0.00347, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 817us/sample - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 43/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00043: val_loss improved from 0.00347 to 0.00345, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 813us/sample - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 44/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00044: val_loss improved from 0.00345 to 0.00343, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 818us/sample - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 45/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00045: val_loss improved from 0.00343 to 0.00340, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 814us/sample - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 46/50\n",
      "150/173 [=========================>....] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00046: val_loss improved from 0.00340 to 0.00337, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 843us/sample - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 47/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00047: val_loss improved from 0.00337 to 0.00335, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 800us/sample - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 48/50\n",
      "160/173 [==========================>...] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00048: val_loss improved from 0.00335 to 0.00333, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 810us/sample - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 49/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00049: val_loss improved from 0.00333 to 0.00331, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 820us/sample - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 50/50\n",
      "155/173 [=========================>....] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00050: val_loss improved from 0.00331 to 0.00328, saving model to model_checkpoints/saved_model.hdf5\n",
      "173/173 [==============================] - 0s 831us/sample - loss: 0.0015 - val_loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/2758 [00:37<7:07:18,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 92.1 ms, sys: 2.59 ms, total: 94.7 ms\n",
      "Wall time: 94.9 ms\n",
      "Train on 174 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "135/174 [======================>.......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00001: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 1s 5ms/sample - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 2/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00002: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 775us/sample - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 3/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00003: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 772us/sample - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 4/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00004: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 766us/sample - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00005: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 754us/sample - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "165/174 [===========================>..] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00006: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 730us/sample - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 7/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00007: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 733us/sample - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 8/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00008: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 748us/sample - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 9/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00009: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 731us/sample - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 10/50\n",
      "150/174 [========================>.....] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00010: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 753us/sample - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 11/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00011: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 753us/sample - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 12/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00012: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 739us/sample - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 13/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00013: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 731us/sample - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 14/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00014: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 735us/sample - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 15/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00015: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 733us/sample - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 16/50\n",
      "145/174 [========================>.....] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00016: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 773us/sample - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 17/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 9.7032e-04\n",
      "Epoch 00017: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 729us/sample - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 18/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00018: val_loss did not improve from 0.00328\n",
      "174/174 [==============================] - 0s 738us/sample - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 19/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00019: val_loss improved from 0.00328 to 0.00328, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 833us/sample - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 20/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00020: val_loss improved from 0.00328 to 0.00326, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 829us/sample - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 21/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00021: val_loss improved from 0.00326 to 0.00325, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 827us/sample - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 22/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00022: val_loss improved from 0.00325 to 0.00323, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 834us/sample - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 23/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00023: val_loss improved from 0.00323 to 0.00322, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 832us/sample - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 24/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00024: val_loss improved from 0.00322 to 0.00320, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 812us/sample - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 25/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00025: val_loss improved from 0.00320 to 0.00319, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 821us/sample - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 26/50\n",
      "150/174 [========================>.....] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00026: val_loss improved from 0.00319 to 0.00317, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 864us/sample - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      "150/174 [========================>.....] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00027: val_loss improved from 0.00317 to 0.00316, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 850us/sample - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00028: val_loss improved from 0.00316 to 0.00314, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 835us/sample - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 29/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00029: val_loss improved from 0.00314 to 0.00313, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 825us/sample - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      "150/174 [========================>.....] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00030: val_loss improved from 0.00313 to 0.00311, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 853us/sample - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 31/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 8.8885e-04\n",
      "Epoch 00031: val_loss improved from 0.00311 to 0.00310, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 829us/sample - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 32/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00032: val_loss improved from 0.00310 to 0.00310, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 847us/sample - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 33/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00033: val_loss improved from 0.00310 to 0.00308, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 838us/sample - loss: 0.0011 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "150/174 [========================>.....] - ETA: 0s - loss: 0.0019   \n",
      "Epoch 00034: val_loss improved from 0.00308 to 0.00307, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 843us/sample - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00035: val_loss improved from 0.00307 to 0.00306, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 807us/sample - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 36/50\n",
      "150/174 [========================>.....] - ETA: 0s - loss: 0.0019   \n",
      "Epoch 00036: val_loss improved from 0.00306 to 0.00305, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 843us/sample - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 37/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00037: val_loss improved from 0.00305 to 0.00304, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 822us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 38/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 8.9880e-04\n",
      "Epoch 00038: val_loss improved from 0.00304 to 0.00304, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 828us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 39/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 4.7730e-04\n",
      "Epoch 00039: val_loss improved from 0.00304 to 0.00303, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 815us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 40/50\n",
      "150/174 [========================>.....] - ETA: 0s - loss: 9.6018e-04\n",
      "Epoch 00040: val_loss improved from 0.00303 to 0.00303, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 844us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "150/174 [========================>.....] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00041: val_loss improved from 0.00303 to 0.00302, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 847us/sample - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 42/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00042: val_loss improved from 0.00302 to 0.00301, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 826us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 43/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00043: val_loss improved from 0.00301 to 0.00299, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 819us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 44/50\n",
      "150/174 [========================>.....] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00044: val_loss improved from 0.00299 to 0.00298, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 837us/sample - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 45/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00045: val_loss improved from 0.00298 to 0.00298, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 833us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 46/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00046: val_loss improved from 0.00298 to 0.00297, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 833us/sample - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 47/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00047: val_loss improved from 0.00297 to 0.00297, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 840us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 48/50\n",
      "160/174 [==========================>...] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00048: val_loss improved from 0.00297 to 0.00296, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 821us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 49/50\n",
      "155/174 [=========================>....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00049: val_loss improved from 0.00296 to 0.00295, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 830us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 50/50\n",
      "145/174 [========================>.....] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00050: val_loss improved from 0.00295 to 0.00294, saving model to model_checkpoints/saved_model.hdf5\n",
      "174/174 [==============================] - 0s 880us/sample - loss: 0.0011 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/2758 [00:46<7:02:04,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 111 ms, sys: 2.74 ms, total: 114 ms\n",
      "Wall time: 113 ms\n",
      "Train on 175 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "140/175 [=======================>......] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00001: val_loss did not improve from 0.00294\n",
      "175/175 [==============================] - 1s 3ms/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 2/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00002: val_loss improved from 0.00294 to 0.00294, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 843us/sample - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "145/175 [=======================>......] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00003: val_loss improved from 0.00294 to 0.00293, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 880us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 4/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00004: val_loss improved from 0.00293 to 0.00293, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 827us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00005: val_loss improved from 0.00293 to 0.00292, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 832us/sample - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00006: val_loss improved from 0.00292 to 0.00292, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 811us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00007: val_loss improved from 0.00292 to 0.00291, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 847us/sample - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 8/50\n",
      "165/175 [===========================>..] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00008: val_loss improved from 0.00291 to 0.00291, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 803us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 9/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00009: val_loss improved from 0.00291 to 0.00291, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 831us/sample - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 10/50\n",
      "160/175 [==========================>...] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00010: val_loss improved from 0.00291 to 0.00290, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 809us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00011: val_loss improved from 0.00290 to 0.00289, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 837us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 12/50\n",
      "145/175 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00012: val_loss improved from 0.00289 to 0.00289, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 857us/sample - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "160/175 [==========================>...] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00013: val_loss improved from 0.00289 to 0.00288, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 820us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 14/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 8.5567e-04\n",
      "Epoch 00014: val_loss improved from 0.00288 to 0.00288, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 832us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 15/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00015: val_loss improved from 0.00288 to 0.00287, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 849us/sample - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 16/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00016: val_loss improved from 0.00287 to 0.00287, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 829us/sample - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 17/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00017: val_loss improved from 0.00287 to 0.00286, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 812us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 18/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00018: val_loss improved from 0.00286 to 0.00286, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 858us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00019: val_loss improved from 0.00286 to 0.00286, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 843us/sample - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00020: val_loss improved from 0.00286 to 0.00285, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 834us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 21/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 9.7623e-04\n",
      "Epoch 00021: val_loss improved from 0.00285 to 0.00285, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 831us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00022: val_loss improved from 0.00285 to 0.00285, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 836us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00023: val_loss improved from 0.00285 to 0.00284, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 840us/sample - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 24/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00024: val_loss improved from 0.00284 to 0.00284, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 844us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00025: val_loss improved from 0.00284 to 0.00284, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 831us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 26/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 8.6708e-04\n",
      "Epoch 00026: val_loss improved from 0.00284 to 0.00284, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 847us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 27/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00027: val_loss improved from 0.00284 to 0.00283, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 818us/sample - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "160/175 [==========================>...] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00028: val_loss improved from 0.00283 to 0.00283, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 828us/sample - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00029: val_loss improved from 0.00283 to 0.00283, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 821us/sample - loss: 0.0014 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 8.9044e-04\n",
      "Epoch 00030: val_loss improved from 0.00283 to 0.00283, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 822us/sample - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00031: val_loss improved from 0.00283 to 0.00283, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 819us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 32/50\n",
      "160/175 [==========================>...] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00032: val_loss improved from 0.00283 to 0.00283, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 812us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00033: val_loss improved from 0.00283 to 0.00283, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 837us/sample - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "160/175 [==========================>...] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00034: val_loss improved from 0.00283 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 807us/sample - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00035: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 843us/sample - loss: 9.6748e-04 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00036: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 835us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 37/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00037: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 827us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 38/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00038: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 829us/sample - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 39/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 0.0010   \n",
      "Epoch 00039: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 830us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 40/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00040: val_loss did not improve from 0.00282\n",
      "175/175 [==============================] - 0s 747us/sample - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "165/175 [===========================>..] - ETA: 0s - loss: 7.8916e-04\n",
      "Epoch 00041: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 807us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00042: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 822us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00043: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 849us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "145/175 [=======================>......] - ETA: 0s - loss: 8.5985e-04\n",
      "Epoch 00044: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 857us/sample - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 45/50\n",
      "145/175 [=======================>......] - ETA: 0s - loss: 8.3308e-04\n",
      "Epoch 00045: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 871us/sample - loss: 9.3169e-04 - val_loss: 0.0028\n",
      "Epoch 46/50\n",
      "160/175 [==========================>...] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00046: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 816us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00047: val_loss improved from 0.00282 to 0.00282, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 822us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 48/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 9.7831e-04\n",
      "Epoch 00048: val_loss improved from 0.00282 to 0.00281, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 807us/sample - loss: 9.1732e-04 - val_loss: 0.0028\n",
      "Epoch 49/50\n",
      "155/175 [=========================>....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00049: val_loss improved from 0.00281 to 0.00281, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 826us/sample - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 50/50\n",
      "150/175 [========================>.....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00050: val_loss improved from 0.00281 to 0.00281, saving model to model_checkpoints/saved_model.hdf5\n",
      "175/175 [==============================] - 0s 840us/sample - loss: 0.0014 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/2758 [00:55<7:02:00,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 101 ms, sys: 4.08 ms, total: 105 ms\n",
      "Wall time: 134 ms\n",
      "Train on 176 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "135/176 [======================>.......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00001: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 1s 5ms/sample - loss: 9.6813e-04 - val_loss: 0.0029\n",
      "Epoch 2/50\n",
      "145/176 [=======================>......] - ETA: 0s - loss: 6.7247e-04\n",
      "Epoch 00002: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 825us/sample - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00003: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 789us/sample - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 4/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 9.9947e-04\n",
      "Epoch 00004: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 748us/sample - loss: 9.2969e-04 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 8.2591e-04\n",
      "Epoch 00005: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 761us/sample - loss: 7.6871e-04 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "150/176 [========================>.....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00006: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 771us/sample - loss: 9.5330e-04 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "165/176 [===========================>..] - ETA: 0s - loss: 0.0010   \n",
      "Epoch 00007: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 735us/sample - loss: 9.9083e-04 - val_loss: 0.0029\n",
      "Epoch 8/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00008: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 752us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 9/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 0.0010   \n",
      "Epoch 00009: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 770us/sample - loss: 9.5619e-04 - val_loss: 0.0029\n",
      "Epoch 10/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 0.0010   \n",
      "Epoch 00010: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 756us/sample - loss: 9.3231e-04 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 8.0934e-04\n",
      "Epoch 00011: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 763us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 12/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00012: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 742us/sample - loss: 9.4403e-04 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00013: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 739us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 14/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00014: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 744us/sample - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 15/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00015: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 759us/sample - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 16/50\n",
      "165/176 [===========================>..] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00016: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 725us/sample - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 17/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 8.3445e-04\n",
      "Epoch 00017: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 765us/sample - loss: 9.3699e-04 - val_loss: 0.0029\n",
      "Epoch 18/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00018: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 743us/sample - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00019: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 735us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00020: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 744us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 21/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 9.6388e-04\n",
      "Epoch 00021: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 748us/sample - loss: 9.1124e-04 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00022: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 754us/sample - loss: 9.3195e-04 - val_loss: 0.0029\n",
      "Epoch 23/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00023: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 753us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 24/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00024: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 737us/sample - loss: 9.3180e-04 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00025: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 769us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 5.7372e-04\n",
      "Epoch 00026: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 741us/sample - loss: 9.3443e-04 - val_loss: 0.0029\n",
      "Epoch 27/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 7.6947e-04\n",
      "Epoch 00027: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 736us/sample - loss: 9.1609e-04 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00028: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 748us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00029: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 748us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00030: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 747us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 31/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00031: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 738us/sample - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00032: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 757us/sample - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 33/50\n",
      "140/176 [======================>.......] - ETA: 0s - loss: 6.5058e-04\n",
      "Epoch 00033: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 829us/sample - loss: 9.1508e-04 - val_loss: 0.0029\n",
      "Epoch 34/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 9.7758e-04\n",
      "Epoch 00034: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 739us/sample - loss: 9.1312e-04 - val_loss: 0.0029\n",
      "Epoch 35/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 9.8095e-04\n",
      "Epoch 00035: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 750us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 36/50\n",
      "155/176 [=========================>....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00036: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 763us/sample - loss: 0.0011 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 9.3986e-04\n",
      "Epoch 00037: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 748us/sample - loss: 8.7945e-04 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 9.7940e-04\n",
      "Epoch 00038: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 738us/sample - loss: 9.1581e-04 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      "150/176 [========================>.....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00039: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 779us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00040: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 726us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 9.4444e-04\n",
      "Epoch 00041: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 710us/sample - loss: 8.8637e-04 - val_loss: 0.0029\n",
      "Epoch 42/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00042: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 714us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00043: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 724us/sample - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 44/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00044: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 724us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 45/50\n",
      "165/176 [===========================>..] - ETA: 0s - loss: 9.7390e-04\n",
      "Epoch 00045: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 712us/sample - loss: 9.4516e-04 - val_loss: 0.0029\n",
      "Epoch 46/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00046: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 725us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 47/50\n",
      "165/176 [===========================>..] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00047: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 710us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 48/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 9.7396e-04\n",
      "Epoch 00048: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 727us/sample - loss: 9.2221e-04 - val_loss: 0.0029\n",
      "Epoch 49/50\n",
      "160/176 [==========================>...] - ETA: 0s - loss: 7.2656e-04\n",
      "Epoch 00049: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 722us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 50/50\n",
      "165/176 [===========================>..] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00050: val_loss did not improve from 0.00281\n",
      "176/176 [==============================] - 0s 714us/sample - loss: 0.0011 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/2758 [01:03<6:53:30,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99.1 ms, sys: 2.91 ms, total: 102 ms\n",
      "Wall time: 132 ms\n",
      "Train on 177 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "135/177 [=====================>........] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00001: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 1s 5ms/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 2/50\n",
      "150/177 [========================>.....] - ETA: 0s - loss: 3.3148e-04\n",
      "Epoch 00002: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 806us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "155/177 [=========================>....] - ETA: 0s - loss: 8.0579e-04\n",
      "Epoch 00003: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 777us/sample - loss: 8.7300e-04 - val_loss: 0.0029\n",
      "Epoch 4/50\n",
      "150/177 [========================>.....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00004: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 777us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00005: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 754us/sample - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "155/177 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00006: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 756us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "155/177 [=========================>....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00007: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 757us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 8/50\n",
      "155/177 [=========================>....] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00008: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 754us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 9/50\n",
      "155/177 [=========================>....] - ETA: 0s - loss: 8.4553e-04\n",
      "Epoch 00009: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 760us/sample - loss: 9.6435e-04 - val_loss: 0.0029\n",
      "Epoch 10/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00010: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 739us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "115/177 [==================>...........] - ETA: 0s - loss: 7.2210e-04\n",
      "Epoch 00011: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 896us/sample - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 12/50\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00012: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 713us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 7.9365e-04\n",
      "Epoch 00013: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 732us/sample - loss: 9.4305e-04 - val_loss: 0.0029\n",
      "Epoch 14/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00014: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 722us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 15/50\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00015: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 709us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 16/50\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 9.8351e-04\n",
      "Epoch 00016: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 721us/sample - loss: 9.3071e-04 - val_loss: 0.0029\n",
      "Epoch 17/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 9.3666e-04\n",
      "Epoch 00017: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 733us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 18/50\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 9.5843e-04\n",
      "Epoch 00018: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 708us/sample - loss: 9.8793e-04 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00019: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 720us/sample - loss: 9.5451e-04 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00020: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 733us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 21/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00021: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 724us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00022: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 715us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 23/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00023: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 715us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 24/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00024: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 720us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00025: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 723us/sample - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "155/177 [=========================>....] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00026: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 734us/sample - loss: 9.8116e-04 - val_loss: 0.0029\n",
      "Epoch 27/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00027: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 733us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00028: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 728us/sample - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "155/177 [=========================>....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00029: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 740us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 8.1839e-04\n",
      "Epoch 00030: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 716us/sample - loss: 9.6610e-04 - val_loss: 0.0029\n",
      "Epoch 31/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00031: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 723us/sample - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 8.0163e-04\n",
      "Epoch 00032: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 715us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 33/50\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 7.6624e-04\n",
      "Epoch 00033: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 713us/sample - loss: 7.2131e-04 - val_loss: 0.0029\n",
      "Epoch 34/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00034: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 735us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 35/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00035: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 724us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 36/50\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00036: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 717us/sample - loss: 0.0012 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 9.3096e-04\n",
      "Epoch 00037: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 709us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 7.7393e-04\n",
      "Epoch 00038: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 708us/sample - loss: 9.2716e-04 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 9.5452e-04\n",
      "Epoch 00039: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 723us/sample - loss: 8.8380e-04 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 7.3323e-04\n",
      "Epoch 00040: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 725us/sample - loss: 8.6232e-04 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 8.7872e-04\n",
      "Epoch 00041: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 703us/sample - loss: 8.2540e-04 - val_loss: 0.0029\n",
      "Epoch 42/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00042: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 715us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00043: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 708us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 44/50\n",
      "115/177 [==================>...........] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00044: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 911us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 45/50\n",
      "155/177 [=========================>....] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00045: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 766us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 46/50\n",
      "155/177 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00046: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 750us/sample - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 47/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00047: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 711us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 48/50\n",
      "160/177 [==========================>...] - ETA: 0s - loss: 9.1763e-04\n",
      "Epoch 00048: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 723us/sample - loss: 8.4351e-04 - val_loss: 0.0029\n",
      "Epoch 49/50\n",
      "150/177 [========================>.....] - ETA: 0s - loss: 9.1885e-04\n",
      "Epoch 00049: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 774us/sample - loss: 8.1261e-04 - val_loss: 0.0029\n",
      "Epoch 50/50\n",
      "155/177 [=========================>....] - ETA: 0s - loss: 6.7828e-04\n",
      "Epoch 00050: val_loss did not improve from 0.00281\n",
      "177/177 [==============================] - 0s 756us/sample - loss: 0.0012 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/2758 [01:12<6:50:21,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 98.1 ms, sys: 3.16 ms, total: 101 ms\n",
      "Wall time: 134 ms\n",
      "Train on 178 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "135/178 [=====================>........] - ETA: 0s - loss: 0.0019   \n",
      "Epoch 00001: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 1s 5ms/sample - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 9.8547e-04\n",
      "Epoch 00002: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 791us/sample - loss: 8.9686e-04 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "145/178 [=======================>......] - ETA: 0s - loss: 8.7313e-04\n",
      "Epoch 00003: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 815us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 4/50\n",
      "145/178 [=======================>......] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00004: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 800us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 5/50\n",
      "145/178 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00005: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 843us/sample - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00006: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 750us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 7/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 9.4218e-04\n",
      "Epoch 00007: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 787us/sample - loss: 8.6592e-04 - val_loss: 0.0028\n",
      "Epoch 8/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00008: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 757us/sample - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 9/50\n",
      "165/178 [==========================>...] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00009: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 709us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 10/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00010: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 784us/sample - loss: 9.2475e-04 - val_loss: 0.0028\n",
      "Epoch 11/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 8.6204e-04\n",
      "Epoch 00011: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 783us/sample - loss: 9.5254e-04 - val_loss: 0.0028\n",
      "Epoch 12/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00012: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 748us/sample - loss: 9.6213e-04 - val_loss: 0.0028\n",
      "Epoch 13/50\n",
      "165/178 [==========================>...] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00013: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 713us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 14/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00014: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 745us/sample - loss: 9.5793e-04 - val_loss: 0.0028\n",
      "Epoch 15/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00015: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 774us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 16/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00016: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 741us/sample - loss: 9.7803e-04 - val_loss: 0.0028\n",
      "Epoch 17/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 5.5206e-04\n",
      "Epoch 00017: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 781us/sample - loss: 7.0376e-04 - val_loss: 0.0028\n",
      "Epoch 18/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 0.0010   \n",
      "Epoch 00018: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 738us/sample - loss: 9.2225e-04 - val_loss: 0.0028\n",
      "Epoch 19/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 3.8831e-04\n",
      "Epoch 00019: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 739us/sample - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 20/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 8.6374e-04\n",
      "Epoch 00020: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 758us/sample - loss: 8.0288e-04 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00021: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 773us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00022: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 770us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00023: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 764us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 24/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00024: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 773us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00025: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 750us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 26/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 0.0010   \n",
      "Epoch 00026: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 766us/sample - loss: 9.1644e-04 - val_loss: 0.0028\n",
      "Epoch 27/50\n",
      "145/178 [=======================>......] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00027: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 766us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 6.2079e-04\n",
      "Epoch 00028: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 746us/sample - loss: 7.5560e-04 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00029: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 748us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00030: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 751us/sample - loss: 9.5096e-04 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 0.0010   \n",
      "Epoch 00031: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 737us/sample - loss: 8.9324e-04 - val_loss: 0.0028\n",
      "Epoch 32/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 9.9569e-04\n",
      "Epoch 00032: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 743us/sample - loss: 9.3275e-04 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "150/178 [========================>.....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00033: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 748us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00034: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 734us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00035: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 718us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 9.8500e-04\n",
      "Epoch 00036: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 723us/sample - loss: 9.1881e-04 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00037: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 729us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 38/50\n",
      "165/178 [==========================>...] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00038: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 710us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 39/50\n",
      "165/178 [==========================>...] - ETA: 0s - loss: 7.3191e-04\n",
      "Epoch 00039: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 705us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 40/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 5.6423e-04\n",
      "Epoch 00040: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 729us/sample - loss: 8.8497e-04 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00041: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 720us/sample - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 6.8014e-04\n",
      "Epoch 00042: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 714us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "165/178 [==========================>...] - ETA: 0s - loss: 7.6466e-04\n",
      "Epoch 00043: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 703us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00044: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 711us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 45/50\n",
      "165/178 [==========================>...] - ETA: 0s - loss: 9.1925e-04\n",
      "Epoch 00045: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 705us/sample - loss: 8.6275e-04 - val_loss: 0.0028\n",
      "Epoch 46/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00046: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 715us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "155/178 [=========================>....] - ETA: 0s - loss: 9.0447e-04\n",
      "Epoch 00047: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 728us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 48/50\n",
      "165/178 [==========================>...] - ETA: 0s - loss: 9.1288e-04\n",
      "Epoch 00048: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 702us/sample - loss: 8.5725e-04 - val_loss: 0.0028\n",
      "Epoch 49/50\n",
      "160/178 [=========================>....] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00049: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 721us/sample - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 50/50\n",
      "165/178 [==========================>...] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00050: val_loss did not improve from 0.00281\n",
      "178/178 [==============================] - 0s 723us/sample - loss: 0.0011 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 9/2758 [01:21<6:48:10,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96.7 ms, sys: 2.79 ms, total: 99.4 ms\n",
      "Wall time: 99.2 ms\n",
      "Train on 179 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "130/179 [====================>.........] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00001: val_loss improved from 0.00281 to 0.00279, saving model to model_checkpoints/saved_model.hdf5\n",
      "179/179 [==============================] - 1s 5ms/sample - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00002: val_loss improved from 0.00279 to 0.00279, saving model to model_checkpoints/saved_model.hdf5\n",
      "179/179 [==============================] - 0s 832us/sample - loss: 9.8701e-04 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00003: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 793us/sample - loss: 9.7018e-04 - val_loss: 0.0028\n",
      "Epoch 4/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00004: val_loss improved from 0.00279 to 0.00279, saving model to model_checkpoints/saved_model.hdf5\n",
      "179/179 [==============================] - 0s 807us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 5/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 7.7933e-04\n",
      "Epoch 00005: val_loss improved from 0.00279 to 0.00279, saving model to model_checkpoints/saved_model.hdf5\n",
      "179/179 [==============================] - 0s 826us/sample - loss: 9.3918e-04 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00006: val_loss improved from 0.00279 to 0.00279, saving model to model_checkpoints/saved_model.hdf5\n",
      "179/179 [==============================] - 0s 853us/sample - loss: 9.6982e-04 - val_loss: 0.0028\n",
      "Epoch 7/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00007: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 764us/sample - loss: 9.5184e-04 - val_loss: 0.0028\n",
      "Epoch 8/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00008: val_loss improved from 0.00279 to 0.00279, saving model to model_checkpoints/saved_model.hdf5\n",
      "179/179 [==============================] - 0s 802us/sample - loss: 9.4745e-04 - val_loss: 0.0028\n",
      "Epoch 9/50\n",
      "145/179 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00009: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 809us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 10/50\n",
      "165/179 [==========================>...] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00010: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 703us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 11/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00011: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 744us/sample - loss: 9.6707e-04 - val_loss: 0.0028\n",
      "Epoch 12/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 9.7724e-04\n",
      "Epoch 00012: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 747us/sample - loss: 9.3820e-04 - val_loss: 0.0028\n",
      "Epoch 13/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00013: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 727us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 14/50\n",
      "165/179 [==========================>...] - ETA: 0s - loss: 8.2300e-04\n",
      "Epoch 00014: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 705us/sample - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 15/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 9.7738e-04\n",
      "Epoch 00015: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 756us/sample - loss: 9.3550e-04 - val_loss: 0.0028\n",
      "Epoch 16/50\n",
      "135/179 [=====================>........] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00016: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 845us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 17/50\n",
      "165/179 [==========================>...] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00017: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 699us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 18/50\n",
      "165/179 [==========================>...] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00018: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 696us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 19/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00019: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 721us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 20/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00020: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 712us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00021: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 719us/sample - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00022: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 717us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00023: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 751us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 24/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 7.9717e-04\n",
      "Epoch 00024: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 768us/sample - loss: 9.2535e-04 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00025: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 751us/sample - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 26/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00026: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 719us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 27/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00027: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 760us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 7.6785e-04\n",
      "Epoch 00028: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 743us/sample - loss: 8.8912e-04 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00029: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 716us/sample - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 9.9820e-04\n",
      "Epoch 00030: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 742us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "165/179 [==========================>...] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00031: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 705us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 32/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00032: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 782us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00033: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 753us/sample - loss: 9.1065e-04 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00034: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 776us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/179 [========================>.....] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00035: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 776us/sample - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 9.9789e-04\n",
      "Epoch 00036: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 756us/sample - loss: 9.1770e-04 - val_loss: 0.0028\n",
      "Epoch 37/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 9.9532e-04\n",
      "Epoch 00037: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 772us/sample - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 38/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00038: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 747us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 39/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 5.7716e-04\n",
      "Epoch 00039: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 750us/sample - loss: 8.8442e-04 - val_loss: 0.0028\n",
      "Epoch 40/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00040: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 751us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00041: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 730us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00042: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 769us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 8.9161e-04\n",
      "Epoch 00043: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 781us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00044: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 758us/sample - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 45/50\n",
      "145/179 [=======================>......] - ETA: 0s - loss: 5.9469e-04\n",
      "Epoch 00045: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 759us/sample - loss: 9.1383e-04 - val_loss: 0.0028\n",
      "Epoch 46/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 9.8762e-04\n",
      "Epoch 00046: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 737us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "150/179 [========================>.....] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00047: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 753us/sample - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 48/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 9.6653e-04\n",
      "Epoch 00048: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 732us/sample - loss: 8.8538e-04 - val_loss: 0.0028\n",
      "Epoch 49/50\n",
      "155/179 [========================>.....] - ETA: 0s - loss: 8.6711e-04\n",
      "Epoch 00049: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 753us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 50/50\n",
      "160/179 [=========================>....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00050: val_loss did not improve from 0.00279\n",
      "179/179 [==============================] - 0s 735us/sample - loss: 0.0010 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 10/2758 [01:30<6:52:01,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 4.5 ms, total: 106 ms\n",
      "Wall time: 126 ms\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "130/180 [====================>.........] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00001: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 2/50\n",
      "150/180 [========================>.....] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00002: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 797us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 3/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00003: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 738us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 4/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00004: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 745us/sample - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "150/180 [========================>.....] - ETA: 0s - loss: 9.5600e-04\n",
      "Epoch 00005: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 764us/sample - loss: 0.0010 - val_loss: 0.0030\n",
      "Epoch 6/50\n",
      "150/180 [========================>.....] - ETA: 0s - loss: 6.9210e-04\n",
      "Epoch 00006: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 754us/sample - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 7/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00007: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 721us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 8/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00008: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 759us/sample - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 9/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 7.7604e-04\n",
      "Epoch 00009: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 742us/sample - loss: 9.0838e-04 - val_loss: 0.0030\n",
      "Epoch 10/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00010: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 733us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 11/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00011: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 718us/sample - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 12/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00012: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 728us/sample - loss: 9.7997e-04 - val_loss: 0.0030\n",
      "Epoch 13/50\n",
      "165/180 [==========================>...] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00013: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 702us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 14/50\n",
      "150/180 [========================>.....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00014: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 767us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 15/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 9.7803e-04\n",
      "Epoch 00015: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 714us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 16/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00016: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 727us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 17/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00017: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 700us/sample - loss: 9.3675e-04 - val_loss: 0.0030\n",
      "Epoch 18/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 7.5881e-04\n",
      "Epoch 00018: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 725us/sample - loss: 0.0010 - val_loss: 0.0030\n",
      "Epoch 19/50\n",
      "150/180 [========================>.....] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00019: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 752us/sample - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 7.6070e-04\n",
      "Epoch 00020: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 722us/sample - loss: 0.0010 - val_loss: 0.0030\n",
      "Epoch 21/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 9.5886e-04\n",
      "Epoch 00021: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 712us/sample - loss: 9.1312e-04 - val_loss: 0.0030\n",
      "Epoch 22/50\n",
      "150/180 [========================>.....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00022: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 765us/sample - loss: 9.4297e-04 - val_loss: 0.0030\n",
      "Epoch 23/50\n",
      "150/180 [========================>.....] - ETA: 0s - loss: 8.2170e-04\n",
      "Epoch 00023: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 784us/sample - loss: 9.1380e-04 - val_loss: 0.0030\n",
      "Epoch 24/50\n",
      "165/180 [==========================>...] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00024: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 696us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 25/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 9.7234e-04\n",
      "Epoch 00025: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 744us/sample - loss: 9.1687e-04 - val_loss: 0.0030\n",
      "Epoch 26/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00026: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 730us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 27/50\n",
      "150/180 [========================>.....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00027: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 745us/sample - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 28/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00028: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 732us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 29/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 7.8228e-04\n",
      "Epoch 00029: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 756us/sample - loss: 8.9233e-04 - val_loss: 0.0030\n",
      "Epoch 30/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00030: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 740us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 31/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 9.3976e-04\n",
      "Epoch 00031: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 715us/sample - loss: 8.7555e-04 - val_loss: 0.0030\n",
      "Epoch 32/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00032: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 712us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 0.0010   \n",
      "Epoch 00033: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 750us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 34/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00034: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 739us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 35/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 7.8437e-04\n",
      "Epoch 00035: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 724us/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 36/50\n",
      "155/180 [========================>.....] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00036: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 745us/sample - loss: 0.0011 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "150/180 [========================>.....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00037: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 756us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 38/50\n",
      "160/180 [=========================>....] - ETA: 0s - loss: 7.0814e-04\n",
      "Epoch 00038: val_loss did not improve from 0.00279\n",
      "180/180 [==============================] - 0s 750us/sample - loss: 8.5888e-04 - val_loss: 0.0030\n",
      "Epoch 39/50\n",
      "  5/180 [..............................] - ETA: 0s - loss: 1.4425e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-912bc4c67851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mburn_in_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m           callbacks = [checkpoints])\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# extract most recent window of features for current time-step prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# day-to-day training and prediction\n",
    "\n",
    "# initialize julia instances\n",
    "j = julia.Julia(compiled_modules=False)\n",
    "\n",
    "# iterate through the remaining time steps\n",
    "for i in tqdm.tqdm(range(len(features)-burn_in_length)):\n",
    "    \n",
    "    # extract training features for the current time-step (includes all instances up to the current time-step)\n",
    "    training_features = features.iloc[0:burn_in_length+i,:]\n",
    "    # extract response variables (log returns) for the current time-step\n",
    "    training_response = log_returns.iloc[0:burn_in_length+i,:]\n",
    "    \n",
    "    # generate training epoch of sliding windows for current time-step\n",
    "    X, y = generate_epoch(training_features, training_response, n_timesteps, look_ahead_time)\n",
    "    \n",
    "    # load latest model weights\n",
    "    model = tf.keras.models.load_model(wkdir + \"model_checkpoints/saved_model.hdf5\")\n",
    "    \n",
    "    # fit to features for current time-step\n",
    "    model.fit(X, y,\n",
    "          validation_split = validation_split,\n",
    "          epochs = burn_in_epochs,\n",
    "          batch_size = batch_size,\n",
    "          callbacks = [checkpoints])\n",
    "    \n",
    "    # extract most recent window of features for current time-step prediction\n",
    "    pred_window = np.array(features.iloc[-n_timesteps:,:]).reshape(1,n_timesteps,features.shape[1])\n",
    "    # extract log returns for the last 'vol_window' time-steps for current 'vol_window'-day volatility\n",
    "    returns_vol_window = np.array(log_returns.iloc[-vol_window:,:])\n",
    "    \n",
    "    # predict mu for tomorrow\n",
    "    mu = model.predict(pred_window)\n",
    "    # find current sigma \n",
    "    sigma = np.dot(np.transpose(returns_vol_window),returns_vol_window)\n",
    "    \n",
    "    # save optimization params to tmp\n",
    "    np.savetxt(\"tmp/mu.txt\",mu)\n",
    "    np.savetxt(\"tmp/sigma.txt\",sigma)\n",
    "    np.savetxt(\"tmp/delta.txt\",delta)\n",
    "    np.savetxt(\"tmp/min_weight.txt\",min_weight)\n",
    "    \n",
    "    # run mvo julia optimizer\n",
    "    %time j.include(\"mvo.jl\")\n",
    "    \n",
    "    # pull in optimal weights from optimizer for rebalancing\n",
    "    with open(\"tmp/weights.txt\", 'r') as f:\n",
    "        w = f.readlines()\n",
    "        weights = [float(e.replace('\\n',\"\")) for e in w]\n",
    "    \n",
    "    # append rebalanced weights to daily_portfolio_weights object\n",
    "    daily_portfolio_weights.append(weights)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.05,\n",
       "  0.05,\n",
       "  0.05000003802197807,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.500000005744744,\n",
       "  0.05,\n",
       "  0.05],\n",
       " [0.05,\n",
       "  0.05,\n",
       "  0.05000007358533766,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.4999999644863063,\n",
       "  0.05,\n",
       "  0.05],\n",
       " [0.05,\n",
       "  0.05,\n",
       "  0.05000016026692852,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.4999998716957945,\n",
       "  0.05,\n",
       "  0.05],\n",
       " [0.05,\n",
       "  0.05,\n",
       "  0.05000030035694267,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.4999997262687899,\n",
       "  0.05,\n",
       "  0.05],\n",
       " [0.05,\n",
       "  0.05,\n",
       "  0.05000172093742162,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.4999983013638237,\n",
       "  0.05,\n",
       "  0.05],\n",
       " [0.05,\n",
       "  0.05,\n",
       "  0.050000500714416564,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.4999995634925719,\n",
       "  0.05,\n",
       "  0.05],\n",
       " [0.05,\n",
       "  0.05,\n",
       "  0.05000429791846216,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.0500000006168396,\n",
       "  0.49999571789940317,\n",
       "  0.05,\n",
       "  0.05000000025830422],\n",
       " [0.05,\n",
       "  0.05,\n",
       "  0.08111618895682647,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.46888387385026176,\n",
       "  0.05,\n",
       "  0.05],\n",
       " [0.05,\n",
       "  0.05,\n",
       "  0.12264662652671161,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.42735343643489543,\n",
       "  0.05,\n",
       "  0.05],\n",
       " [0.05,\n",
       "  0.05,\n",
       "  0.4999901630256952,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05,\n",
       "  0.05000989986253993,\n",
       "  0.05,\n",
       "  0.05]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_portfolio_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Mini-batch gradient descent:\n",
    "\n",
    "def fetch_batch(batch_instance, batch_size, features, log_returns, n_timesteps, look_ahead_time):\n",
    "    \n",
    "    \"\"\"\n",
    "    batch_instance: which batch we are in out of the total number of batches in the epoch (starts from 0)\n",
    "    batch_size: the number of instances in each batch\n",
    "    n_timesteps: length of series used for prediction (i.e. how many days we're predict off of)\n",
    "    look_ahead_time: number of days in advance we will predict\n",
    "    features: features matrix\n",
    "    log_returns: response var matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # begin with empty arrays to which we will append \n",
    "    X = np.array([]) \n",
    "    y = np.array([])\n",
    "    \n",
    "    for i in range((batch_instance*batch_size), (batch_instance*batch_size) + batch_size):\n",
    "        \n",
    "        ### e.g.: range[0,20), range[20,40), range[40,60) etc if batch_size is 20 ###\n",
    "        ### note that range function is NOT inclusive of last integer ###\n",
    "        \n",
    "        end_index = i + n_timesteps\n",
    "        \n",
    "        ### e.g.: end_index = 0 + 10 = 10 for first batch instance and n_timesteps = 10 ###\n",
    "        \n",
    "        # return (X_one:[n_timesteps,n_features], y_one:[look_ahead_time, n_assets]) starting on day 'i'\n",
    "        X_one, y_one = sliding_window(features, log_returns, end_index, n_timesteps, look_ahead_time)\n",
    "        \n",
    "        # append X_one:[n_timesteps,n_features] to batch ndarray X\n",
    "        X = np.append(X,X_one)\n",
    "        # append y_one:[look_ahead_time, n_assets] to batch ndarray y\n",
    "        y = np.append(y,y_one)\n",
    "    \n",
    "    # reshape to 3D with number_of_batch_instances x n_time_steps x n_features\n",
    "    X = X.reshape(batch_size, n_timesteps, features.shape[1])\n",
    "    # reshape to 2D with number_of_batch_instances x n_features\n",
    "    y = y.reshape(batch_size, log_returns.shape[1])\n",
    "    \n",
    "    return X, y \n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# start by iterating through epochs\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # then iterate through n_batches\n",
    "    for batch_instance in range(n_batches):\n",
    "        \n",
    "        # fetch the batches\n",
    "        X_batch, y_batch = fetch_batch(batch_instance, batch_size, features, \n",
    "                                       log_returns, n_timesteps, look_ahead_time)\n",
    "        \n",
    "        # fit batches to model\n",
    "        model.fit(X_batch, y_batch, batch_size=batch_size)\n",
    "        \n",
    "\"\"\"       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
